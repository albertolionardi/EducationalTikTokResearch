{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "# Function to calculate average value\n",
    "def calculate_average(lower, upper):\n",
    "    return (lower + upper) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BY AGE ; GENDER; EDUCATIONAL CONTENT ###\n",
    "\n",
    "### EDUCATIONAL CONTENT ACROSS REGENCIES ###\n",
    "\n",
    "accountId = 'your_account_id'\n",
    "cookies = {\n",
    "}\n",
    "\n",
    "headers = {'your_headers'\n",
    "}\n",
    "\n",
    "params = { 'your_params_here'\n",
    "}\n",
    "\n",
    "age_groups = [\n",
    "    [18,24],\n",
    "    [25,34],\n",
    "    [35,44],\n",
    "    [45,54],\n",
    "    [55,100]\n",
    "]\n",
    "language_content = {\n",
    "    'English , Indonesia' : ['en' , 'id'],\n",
    "    'English' : ['en'],\n",
    "    'Indonesia': ['id'],\n",
    "}\n",
    "gender = {'Male': '1' , 'Female' : '2'}\n",
    "\n",
    "country = {'Indonesia' : ['1643084']}\n",
    "locations = {\n",
    "    'West Sumatera': ['1626197'],\n",
    "    'Aceh': ['1215638'],\n",
    "    'Badung': ['7038902'],\n",
    "    'Buleleng': ['1647803'],\n",
    "    'Denpasar': ['1645528'],\n",
    "    'Gianyar Tabanan': ['1644099', '1625708'],\n",
    "    'Bangka Belitung Islands' : ['1923047'],\n",
    "    'Cilegon Lebak': ['1646511', '7761456'],\n",
    "    'Pandeglang': ['1632823'],\n",
    "    'Serang': ['1627549'],\n",
    "    'Serang City': ['9845383'],\n",
    "    'South Tangerang': ['8581443'],\n",
    "    'Tangerang': ['1625084'],\n",
    "    'Tangerang Kota': ['9849891'],\n",
    "    'Bengkulu': ['1649147'],\n",
    "    'Central Jakarta': ['6754874'],\n",
    "    'East Jakarta': ['1642904'],\n",
    "    'North Jakarta ': ['1642903'],\n",
    "    'South Jakarta': ['1642905'],\n",
    "    'West Jakarta': ['1642909'],\n",
    "    'Gorontalo': ['1923046'],\n",
    "    'Jambi': ['1642858', '8741042' , '9845496'],\n",
    "    'Bandung': ['1650352'],\n",
    "    'Bandung2': ['1650357'],\n",
    "    'Bekasi': ['1649377'],\n",
    "    'Bekasi City': ['1649378'],\n",
    "    'Bogor': ['1648471'],\n",
    "    'Bogor2': ['1648473'],\n",
    "    'Ciamis': ['1647149'],\n",
    "    'Cianjur Cimahi': ['1647142' , '6591034'],\n",
    "    'Cirebon': ['1646169' , '1646170'],\n",
    "    'Depok': ['6605829'],\n",
    "    'Garut': ['1644409'],\n",
    "    'Indramayu': ['1643078'],\n",
    "    'Karawang': ['1641134'],\n",
    "    'Kuningan': ['1639094'],\n",
    "    'Majalengka': ['1636816'],\n",
    "    'Purwakarta': ['1630341'],\n",
    "    'Subang': ['1626444'],\n",
    "    'Sukabumi': ['1626380', '1626381'],\n",
    "    'Sumedang': ['1626103'],\n",
    "    'Tasikmalaya': ['1624646'],\n",
    "    'Tasikmalaya City': ['1624647'],\n",
    "    'West Bandung': ['7910336'],\n",
    "    'Banjarnegara': ['6379100'],\n",
    "    'Banyumas': ['1650095'],\n",
    "    'Batang Blora': ['1649881', '1648568'],\n",
    "    'Boyolali': ['1648084'],\n",
    "    'Brebes': ['1648065'],\n",
    "    'Cilacap': ['1646559'],\n",
    "    'Demak': ['1645559'],\n",
    "    'Grobogan': ['1643770'],\n",
    "    'Jepara': ['1642548'],\n",
    "    'Karanganyar': ['6380762'],\n",
    "    'Kebumen': ['6380810'],\n",
    "    'Kendal': ['1640350'],\n",
    "    'Klaten': ['1639900'],\n",
    "    'Kudus': ['1639215'],\n",
    "    'Magelang': ['1636884'],\n",
    "    'Pati': ['1631992'],\n",
    "    'Pekalongan': ['6792336', '1631766'],\n",
    "    'Pemalang': ['1631648'],\n",
    "    'Purbalingga': ['1630366'],\n",
    "    'Purworejo': ['6740029'],\n",
    "    'Rembang': ['8060713'],\n",
    "    'Semarang': ['1627896'],\n",
    "    'Semarang2': ['6410701'],\n",
    "    'Sragen': ['1626498'],\n",
    "    'Sukoharjo': ['6827913'],\n",
    "    'Surakarta': ['1625812'],\n",
    "    'Tegal, Temanggung': ['1624494', '1624238'],\n",
    "    'Wonogiri': ['1621431'],\n",
    "    'Wonosobo': ['6792451'],\n",
    "    'Banyuwangi Bangkalan': ['1650077' , '1650298'],\n",
    "    'Batu Blitar': ['1649824', '1648579' , '1648580'],\n",
    "    'Bojonegoro And Bondowoso': ['1648451', '1648266'],\n",
    "    'Gresik': ['1643776'],\n",
    "    'Jember': ['1642588'],\n",
    "    'Jombang': ['1642414'],\n",
    "    'Kediri': ['1640657' , '1640660'],\n",
    "    'Lamongan': ['1638562'],\n",
    "    'Lumajang': ['1637090'],\n",
    "    'Madiun': ['1636929' , '1636930'],\n",
    "    'Magetan': ['1636878'],\n",
    "    'Malang': ['1636713' , '1636722'],\n",
    "    'Mojokerto': ['1635110'],\n",
    "    'Nganjuk': ['1634131'],\n",
    "    'Ngawi , Pacitan, Pamekasan': ['1634098' , '7051297'],\n",
    "    'Pasuruan': ['1632032'],\n",
    "    'Ponorogo': ['1630798'],\n",
    "    'Probolinggo': ['1630633', '1630634'],\n",
    "    'Sidoarjo, Sampang': ['1627253', '1628899'],\n",
    "    'Situbondo, Sumenep': ['1626801', '1626099'],\n",
    "    'Surabaya': ['1625822'],\n",
    "    'Trenggalek': ['1623251'],\n",
    "    'Tuban': ['1623180'],\n",
    "    'Tulungagung': ['1623080'],\n",
    "    'Ketapang': ['1640135'],\n",
    "    'Kubu Raya': ['9828037'],\n",
    "    'Pontianak': ['1630789'],\n",
    "    'Sambas, ': ['1628979'],\n",
    "    'Sanggau, Sintang ': ['1628802', '1626887'],\n",
    "    'Banjarbaru , Banjar': ['1650217' , '1215481'],\n",
    "    'Banjarmasin': ['1650213'],\n",
    "    'Tanah Bumbu, Tanah Laut': ['9780988', '1625166'],\n",
    "    'East Kotawaringin': ['1639475'],\n",
    "    'Palangkaraya': ['1633118'],\n",
    "    'Pulang Pisau': ['1630555'],\n",
    "    'West Kotawaringin': ['1639476'],\n",
    "    'Balikpapan': ['1650527'],\n",
    "    'Berau': ['1649040'],\n",
    "    'East Kutai': ['9846668'],\n",
    "    'Kutai Kartanegara': ['9828039'],\n",
    "    'Paser': ['9843600'],\n",
    "    'Samarinda, West Kutai': ['1629001', '9828038'],\n",
    "    'North Kalimantan': ['8604684'],\n",
    "    'Batam': ['8314434'],\n",
    "    'Tanjung Pinang': ['1624863'],\n",
    "    'Bandar Lampung': ['1624917'],\n",
    "    'Central Lampung': ['1638532'],\n",
    "    'East Lampung': ['9165778'],\n",
    "    'North Lampung, Pesawaran': ['1638531', '9843606'],\n",
    "    'South Lampung': ['7862296'],\n",
    "    'Ambon': ['1636627'],\n",
    "    'North Maluku': ['1958070'],\n",
    "    'Central Lombok': ['1637366'],\n",
    "    'East Lombok': ['1637365'],\n",
    "    'Mataram , Sumbawa': ['1635882', '1626188'],\n",
    "    'West Lombok': ['1637367'],\n",
    "    'Kupang': ['2057086', '2057087'],\n",
    "    'Bengkalis': ['1649169'],\n",
    "    'Dumai': ['1645133'],\n",
    "    'Indragiri Hilir, Hulu': ['1643082', '1643081'],\n",
    "    'Kampar': ['6724577'],\n",
    "    'Pekanbaru, Siak': ['1631761' , '9844901'],\n",
    "    'Pelalawan': ['1631724'],\n",
    "    'Rokan Hilir': ['9844900'],\n",
    "    'Rokan Hulu': ['6722476'],\n",
    "    'Jayapura': ['2082600', '7910936'],\n",
    "    'Sorong': ['9845465', '1626542'],  \n",
    "    'Bantul': ['1650119'],     \n",
    "    'Gunungkidul, Kulon Progo': ['1643604', '7910930'],     \n",
    "    'Sleman': ['1626754'],     \n",
    "    'Yogyakarta': ['1621177'],     \n",
    "    'West Sulawesi': ['1996550'],\n",
    "    'South Sulawesi': ['1626232'],\n",
    "    'Banggai': ['1650328'],\n",
    "    'Palu': ['1633034'],\n",
    "    'Southeast Sulawesi': ['1626230'],\n",
    "    'North Sulawesi': ['1626229'],\n",
    "    'Banyuasin': ['9165775'],\n",
    "    'Muara Enim': ['1634891'],\n",
    "    'Musi Banyuasin': ['1634644'],\n",
    "    'Ogan Komering Ilir, Ulu': ['1633659', '1633658'],\n",
    "    'Palembang': ['1633070'],\n",
    "    'Asahan': ['6703622'],\n",
    "    'Binjai, Dairi': ['1648725', '1215221'],\n",
    "    'Deli Serdang, Karo, Serdai Bergadang': ['8432597', '1214929', '6715130'],\n",
    "    'Labuhanbatu': ['1638867'],\n",
    "    'Langkat': ['1214728'],\n",
    "    'Medan': ['1214520'],\n",
    "    'Pematangsiantar': ['1214204'],\n",
    "    'Simalungun': ['6716417']\n",
    "}\n",
    "regencies = {\n",
    "    \"Padang\": ['1633419'],\n",
    "    \"Pesisir Selatan\": ['1631300'],\n",
    "    \"Pasaman Barat\": ['9163116'],\n",
    "    \"Agam\": ['1651856'],\n",
    "    \"Aceh Besar\": ['1215635'],\n",
    "    \"Banda Aceh\": ['1215502'],\n",
    "    \"Bireuen\": ['1215350'],\n",
    "    \"Aceh Utara\": ['1215630'],\n",
    "    \"Pidie\": ['8571913'],\n",
    "    \"Badung\": ['7038902'],\n",
    "    \"Buleleng\": ['1647803'],\n",
    "    \"Denpasar\": ['1645528'],\n",
    "    \"Gianyar\": ['1644099'],\n",
    "    \"Tabanan\": ['1625708'],\n",
    "    \"Bangka\": ['1650314'],\n",
    "    \"Pangkal Pinang\": ['1632654'],\n",
    "    \"Cilegon\": ['1646511'],\n",
    "    \"Lebak\": ['7761456'],\n",
    "    \"Pandeglang\": ['1632823'],\n",
    "    \"Serang\": ['1627549'],\n",
    "    \"Kota Serang\": ['9845383'],\n",
    "    \"Tangerang Selatan\": ['8581443'],\n",
    "    \"Tangerang\": ['1625084'],\n",
    "    \"Tangerang Kota\": ['9849891'],\n",
    "    \"Bengkulu\": ['1649150'],\n",
    "    \"Bengkulu Utara\": ['1649145'],\n",
    "    \"Bengkulu Selatan\": ['1649146'],\n",
    "    \"Central Jakarta\": ['6754874'],\n",
    "    \"Jakarta Timur\": ['1642904'],\n",
    "    \"Jakarta Utara\": ['1642903'],\n",
    "    \"Jakarta Selatan\": ['1642905'],\n",
    "    \"Jakarta Barat\": ['1642909'],\n",
    "    \"Gorontalo\": ['1643837'],\n",
    "    \"Gorontalo Kota\": ['1643836'],\n",
    "    \"Jambi\": ['1642858'],\n",
    "    \"Muaro Jambi\": ['8741042'],\n",
    "    \"Tanjung Jabung Barat\": ['9845496'],\n",
    "    \"Bandung\": ['1650352'],\n",
    "    \"Bandung2\": ['1650357'],\n",
    "    \"Bekasi\": ['1649377'],\n",
    "    \"Bekasi City\": ['1649378'],\n",
    "    \"Bogor\": ['1648471'],\n",
    "    \"Bogor2\": ['1648473'],\n",
    "    \"Ciamis\": ['1647149'],\n",
    "    \"Cianjur\": ['1647142'],\n",
    "    \"Cimahi\": ['6591034'],\n",
    "    \"Cirebon\": ['1646169'],\n",
    "    \"Cirebon City\": ['1646170'],\n",
    "    \"Depok\": ['6605829'],\n",
    "    \"Garut\": ['1644409'],\n",
    "    \"Indramayu\": ['1643078'],\n",
    "    \"Karawang\": ['1641134'],\n",
    "    \"Kuningan\": ['1639094'],\n",
    "    \"Majalengka\": ['1636816'],\n",
    "    \"Pangandaran\": ['1632790'],\n",
    "    \"Purwakarta\": ['1630341'],\n",
    "    \"Subang\": ['1626444'],\n",
    "    \"Sukabumi\": ['1626380'],\n",
    "    \"Sukabumi City\": ['1626381'],\n",
    "    \"Sumedang\": ['1626103'],\n",
    "    \"Tasikmalaya\": ['1624646'],\n",
    "    \"Tasikmalaya City\": ['1624647'],\n",
    "    \"West Bandung\": ['7910336'],\n",
    "    \"Banjarnegara\": ['6379100'],\n",
    "    \"Banyumas\": ['1650095'],\n",
    "    \"Batang\": ['1649881'],\n",
    "    \"Blora\": ['1648568'],\n",
    "    \"Boyolali\": ['1648084'],\n",
    "    \"Brebes\": ['1648065'],\n",
    "    \"Cilacap\": ['1646559'],\n",
    "    \"Demak\": ['1645559'],\n",
    "    \"Grobogan\": ['1643770'],\n",
    "    \"Jepara\": ['1642548'],\n",
    "    \"Karanganyar\": ['6380762'],\n",
    "    \"Kebumen\": ['6380810'],\n",
    "    \"Kendal\": ['1640350'],\n",
    "    \"Klaten\": ['1639900'],\n",
    "    \"Kudus\": ['1639215'],\n",
    "    \"Magelang\": ['1636884'],\n",
    "    \"Pati\": ['1631992'],\n",
    "    \"Pekalongan\": ['6792336'],\n",
    "    \"Pekalongan City\": ['1631766'],\n",
    "    \"Pemalang\": ['1631648'],\n",
    "    \"Purbalingga\": ['1630366'],\n",
    "    \"Purworejo\": ['6740029'],\n",
    "    \"Rembang\": ['8060713'],\n",
    "    \"Semarang\": ['1627896'],\n",
    "    \"Semarang2\": ['6410701'],\n",
    "    \"Sragen\": ['1626498'],\n",
    "    \"Sukoharjo\": ['6827913'],\n",
    "    \"Surakarta\": ['1625812'],\n",
    "    \"Tegal\": ['1624494'],\n",
    "    \"Temanggung\": ['1624238'],\n",
    "    \"Wonogiri\": ['1621431'],\n",
    "    \"Wonosobo\": ['6792451'],\n",
    "    \"Bangkalan\": ['1650298'],\n",
    "    \"Banyuwangi\": ['1650077'],\n",
    "    \"Batu\": ['1649824'],\n",
    "    \"Blitar\": ['1648579'],\n",
    "    \"Blitar City\": ['1648580'],\n",
    "    \"Bojonegoro\": ['1648451'],\n",
    "    \"Bondowoso\": ['1648266'],\n",
    "    \"Gresik\": ['1643776'],\n",
    "    \"Jember\": ['1642588'],\n",
    "    \"Jombang\": ['1642414'],\n",
    "    \"Kediri\": ['1640657'],\n",
    "    \"Kediri City\": ['1640660'],\n",
    "    \"Lamongan\": ['1638562'],\n",
    "    \"Lumajang\": ['1637090'],\n",
    "    \"Madiun\": ['1636929'],\n",
    "    \"Madiun City\": ['1636930'],\n",
    "    \"Magetan\": ['1636878'],\n",
    "    \"Malang\": ['1636713'],\n",
    "    \"Malang City\": ['1636722'],\n",
    "    \"Mojokerto\": ['1635110'],\n",
    "    \"Nganjuk\": ['1634131'],\n",
    "    \"Ngawi\": ['1634098'],\n",
    "    \"Pacitan\": ['7051297'],\n",
    "    \"Pamekasan\": ['1632978'],\n",
    "    \"Pasuruan\": ['1632032'],\n",
    "    \"Ponorogo\": ['1630798'],\n",
    "    \"Probolinggo\": ['1630633'],\n",
    "    \"Probolinggo City\": ['1630634'],\n",
    "    \"Sampang\": ['1628899'],\n",
    "    \"Sidoarjo\": ['1627253'],\n",
    "    \"Situbondo\": ['1626801'],\n",
    "    \"Sumenep\": ['1626099'],\n",
    "    \"Surabaya\": ['1625822'],\n",
    "    \"Trenggalek\": ['1623251'],\n",
    "    \"Tuban\": ['1623180'],\n",
    "    \"Tulungagung\": ['1623080'],\n",
    "    \"Ketapang\": ['1640135'],\n",
    "    \"Kubu Raya\": ['9828037'],\n",
    "    \"Pontianak\": ['1630789'],\n",
    "    \"Sambas\": ['1628979'],\n",
    "    \"Sanggau\": ['1628802'],\n",
    "    \"Sintang\": ['1626887'],\n",
    "    \"Banjar\": ['1215481'],\n",
    "    \"Banjarbaru\": ['1650217'],\n",
    "    \"Banjarmasin\": ['1650213'],\n",
    "    \"Tanah Bumbu\": ['9780988'],\n",
    "    \"Tanah Laut\": ['1625166'],\n",
    "    \"East Kotawaringin\": ['1639475'],\n",
    "    \"Palangkaraya\": ['1633118'],\n",
    "    \"Pulang Pisau\": ['1630555'],\n",
    "    \"West Kotawaringin\": ['1639476'],\n",
    "    \"Balikpapan\": ['1650527'],\n",
    "    \"Berau\": ['1649040'],\n",
    "    \"East Kutai\": ['9846668'],\n",
    "    \"Kutai Kartanegara\": ['9828039'],\n",
    "    \"Paser\": ['9843600'],\n",
    "    \"Samarinda\": ['1629001'],\n",
    "    \"West Kutai\": ['9828038'],\n",
    "    \"Tarakan\": ['8604684'],\n",
    "    \"Batam\": ['8314434'],\n",
    "    \"Tanjung Pinang\": ['1624863'],\n",
    "    \"Bandar Lampung\": ['1624917'],\n",
    "    \"Central Lampung\": ['1638532'],\n",
    "    \"East Lampung\": ['9165778'],\n",
    "    \"North Lampung\": ['1638531'],\n",
    "    \"Pesawaran\": ['9843606'],\n",
    "    \"South Lampung\": ['7862296'],\n",
    "    \"Ambon\": ['1636627'],\n",
    "    \"Ternate\": ['1624041'],\n",
    "    \"Kepulauan Tidore\": ['9845501'],\n",
    "    \"Central Lombok\": ['1637366'],\n",
    "    \"East Lombok\": ['1637365'],\n",
    "    \"Mataram\": ['1635882'],\n",
    "    \"Sumbawa\": ['1626188'],\n",
    "    \"West Lombok\": ['1637367'],\n",
    "    \"Kupang\": ['2057086'],\n",
    "    \"Kupang2\": ['2057087'],\n",
    "    \"Bengkalis\": ['1649169'],\n",
    "    \"Dumai\": ['1645133'],\n",
    "    \"Indragiri Hilir\": ['1643082'],\n",
    "    \"Indragiri Hulu\": ['1643081'],\n",
    "    \"Kampar\": ['6724577'],\n",
    "    \"Pekanbaru\": ['1631761'],\n",
    "    \"Pelalawan\": ['1631724'],\n",
    "    \"Rokan Hilir\": ['9844900'],\n",
    "    \"Rokan Hulu\": ['6722476'],\n",
    "    \"Siak\": ['9844901'],\n",
    "    \"Jayapura\": ['2082600'],\n",
    "    \"Kota Jayapura\": ['7910936'],\n",
    "    \"Sorong\": ['9845465'],\n",
    "    \"Sorong City\": ['1626542'],\n",
    "    \"Bantul\": ['1650119'],\n",
    "    \"Gunungkidul\": ['1643604'],\n",
    "    \"Kulon Progo\": ['7910930'],\n",
    "    \"Sleman\": ['1626754'],\n",
    "    \"Yogyakarta\": ['1621177'],\n",
    "    \"Mamuju\": ['1636556'],\n",
    "    \"Pollewali Mandar\": ['1630933'],\n",
    "    \"Bone\": ['1621437'],\n",
    "    \"Gowa\": ['1643807'],\n",
    "    \"Makassar\": ['1622786'],\n",
    "    \"Maros\": ['1636029'],\n",
    "    \"Pinrang\": ['1631103'],\n",
    "    \"Wajo\": ['1622267'],\n",
    "    \"Banggai\": ['1650328'],\n",
    "    \"Palu\": ['1633034'],\n",
    "    \"Kendari\": ['1640344'],\n",
    "    \"Konawe\": ['1976792'],\n",
    "    \"Manado\": ['1636544'],\n",
    "    \"Minahasa\": ['6755517'],\n",
    "    \"Banyuasin\": ['9165775'],\n",
    "    \"East Ogan Komering Ulu\": ['9166051'],\n",
    "    \"Muara Enim\": ['1634891'],\n",
    "    \"Musi Banyuasin\": ['1634644'],\n",
    "    \"Ogan Komering Ilir\": ['1633659'],\n",
    "    \"Ogan Komering Ulu\": ['1633658'],\n",
    "    \"Palembang\": ['1633070'],\n",
    "    \"Asahan\": ['6703622'],\n",
    "    \"Binjai\": ['1648725'],\n",
    "    \"Dairi\": ['1215221'],\n",
    "    \"Deli Serdang\": ['8432597'],\n",
    "    \"Karo\": ['1214929'],\n",
    "    \"Labuhanbatu\": ['1638867'],\n",
    "    \"Langkat\": ['1214728'],\n",
    "    \"Medan\": ['1214520'],\n",
    "    \"Pematangsiantar\": ['1214204'],\n",
    "    \"Serdang Bedagai\": ['6715130'],\n",
    "    \"Simalungun\": ['6716417']\n",
    "}\n",
    "provinces = {\n",
    "    \"Aceh\": [\"1215638\"],\n",
    "    \"Bali\": [\"1650535\"],\n",
    "    \"Bangka Belitung Islands\": [\"1923047\"],\n",
    "    \"Banten\": [\"1923045\"],\n",
    "    \"Bengkulu\": [\"1649147\"],\n",
    "    \"Central Java\": [\"1642669\"],\n",
    "    \"Central Kalimantan\": [\"1641898\"],\n",
    "    \"Central Sulawesi\": [\"1626231\"],\n",
    "    \"East Java\": [\"1642668\"],\n",
    "    \"East Kalimantan\": [\"1641897\"],\n",
    "    \"East Nusa Tenggara\": [\"1633791\"],\n",
    "    \"Gorontalo\": [\"1923046\"],\n",
    "    \"Jakarta\": [\"1642907\"],\n",
    "    \"Jambi\": [\"1642856\"],\n",
    "    \"Lampung\": [\"1638535\"],\n",
    "    \"Maluku\": [\"1636627\"],\n",
    "    \"North Kalimantan\": [\"8604684\"],\n",
    "    \"North Maluku\": [\"1958070\"],\n",
    "    \"North Sulawesi\": [\"1626229\"],\n",
    "    \"North Sumatra\": [\"1213642\"],\n",
    "    \"Papua\": [\"1643012\"],\n",
    "    \"Riau\": [\"1629652\"],\n",
    "    \"Riau Islands\": [\"1996551\"],\n",
    "    \"South Kalimantan\": [\"1641899\"],\n",
    "    \"South Sulawesi\": [\"1626232\"],\n",
    "    \"South Sumatra\": [\"1626196\"],\n",
    "    \"Southeast Sulawesi\": [\"1626230\"],\n",
    "    \"West Java\": [\"1642672\"],\n",
    "    \"West Kalimantan\": [\"1641900\"],\n",
    "    \"West Nusa Tenggara\": [\"1633792\"],\n",
    "    \"West Papua\": [\"1996549\"],\n",
    "    \"West Sulawesi\": [\"1996550\"],\n",
    "    \"West Sumatra\": [\"1626197\"],\n",
    "    \"Yogyakarta\": [\"1621176\"]\n",
    "}\n",
    "\n",
    "Json_Data = {\"with_signature\":False,\n",
    "\"inventory_flow\":[\"3000\"],\n",
    "\"ad_ref_app_id\":\"\",\n",
    "\"ad_ref_pixel_id\":\"\",\n",
    "\"op_sys_filter\":0,\n",
    "\"optimize_goal\":103,\n",
    "\"external_type\":602,\n",
    "\"objective_type\":5,\n",
    "\"audience\":{\"ad_tag_v2\":[],\n",
    "            \"interest_keywords_i18n\":[],\n",
    "            \"in_market_tags\":[],\n",
    "            \"action_scenes_v2\":[13],\n",
    "            \"video_actions_v2\":[[6]],\n",
    "            \"action_categories_v2\":[],\n",
    "            \"action_days_v2\":[0],\n",
    "            \"contextual_tags\":[],\n",
    "            \"platform\":[\"0\"],\n",
    "            \"device_models\":[],\n",
    "            \"automated_targeting\":0,\n",
    "            \"target_device_version\":0,\n",
    "            \"retargeting_tags\":[],\n",
    "            \"retargeting_tags_exclude\":[],\n",
    "            \"particle_locations\":[],\n",
    "            \"zipcode_ids\":[],\n",
    "            \"gender\":\"0\",\n",
    "            \"age\":[],\n",
    "            \"spending_power_v2\":[],\n",
    "            \"ac\":[],\n",
    "            \"language_list\":[],\n",
    "            \"household_income\":[],\n",
    "            \"android_osv\":\"\",\n",
    "            \"ios_osv\":\"\",\n",
    "            \"carriers\":[],\n",
    "            \"internet_service_providers\":[],\n",
    "            \"targeting_expansion\":{\"expansion_enabled\":False,\n",
    "                                \"expansion_types\":[]},\n",
    "        \"launch_price\":[],\n",
    "        \"flow_package_include\":[],\n",
    "        \"flow_package_exclude\":[],\n",
    "        \"app_retargeting_install\":False,\n",
    "        \"app_retargeting_type\":None,\n",
    "        \"retargeting_audience_rule\":None}\n",
    "        }\n",
    "\n",
    "def request_tiktok(cookies, headers, Json_Data, LocID = None, LanguageList = None, ageList = None , device = None, connectionType = None, GenID = None , hashTagID = None ):\n",
    "    Json_Data['audience']['particle_locations'] = LocID\n",
    "    if LanguageList is not None : \n",
    "        Json_Data['audience']['language_list'] = LanguageList\n",
    "    if ageList is not None : \n",
    "        Json_Data['audience']['age'] = [ageList]\n",
    "    if device is not None :\n",
    "        Json_Data['audience']['platform'] = [device]\n",
    "    if GenID is not None : \n",
    "        Json_Data['audience']['gender'] = GenID\n",
    "    if connectionType is not None :\n",
    "        Json_Data['audience']['ac'] = connectionType\n",
    "    if hashTagID is not None :     \n",
    "        Json_Data['audience']['action_categories_v2'] = hashTagID\n",
    "    print(Json_Data)\n",
    "    response = requests.post(\n",
    "    'api_url',\n",
    "    cookies=cookies,\n",
    "    headers=headers,\n",
    "    json=Json_Data,\n",
    "    )\n",
    "    return response.content.decode('utf-8'), response.status_code\n",
    "\n",
    "def get_upper_lower(response_string):\n",
    "    if response_string:\n",
    "        try:\n",
    "            output_result = json.loads(response_string)\n",
    "            lower = output_result['data']['upper_user_count']\n",
    "            upper = output_result['data']['lower_user_count']\n",
    "            return upper, lower\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Empty response received\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "population_data_per_regency_ordered = np.array([\n",
    "    919145, 516518, 442479, 540905,\n",
    "    414490, 257635, 443874, 614640, 444505,\n",
    "    558100, 802800, 741000, 520900, 464500,\n",
    "    334344, 226297,\n",
    "    445060, 1417350, 1298850, 1661370, 712410, 1378710, 3321650, 1931640,\n",
    "    384841, 302833, 170093,\n",
    "    1053482, 3066074, 1799220, 2234262, 2458707,\n",
    "    398801, 201350,\n",
    "    619600, 412800, 324500,\n",
    "    3718660, 1650357, 3214791, 2590257, 5390000, 1648473, 1247768, 2542793, 575235, 2315417, 341235, 2123349, 2627220, 1871832, 2505247, 1196017, 1335460, 432380, 1028569, 1624386, 2806664, 356410, 1167033, 1906288, 733467, 1846969,\n",
    "    1038718, 1806013, 813791, 888224, 1079952, 2010617, 1988622, 1223217, 1470150, 1192811, 947642, 1376825, 1033367, 1275850, 856472, 1312573, 1339572, 986455, 309742, 1500754, 1019840, 778257, 650770, 1068492, 1659975, 992243, 916627, 523008, 278299, 799764, 1057087, 896346,\n",
    "    1086620, 1731731, 216735, 1240322, 151960, 1315125, 781417, 1332664, 2567718, 1335972, 1656020, 289418, 1371509, 1137227, 757665, 199192, 678343, 2685900, 846126, 1133584, 1117033, 877432, 592916, 857818, 1619035, 964253, 1159965, 243200, 984162, 2103401, 691260, 1136632, 2887223, 739669, 1209543, 1105337,\n",
    "    591917, 622217, 669795, 647844, 492989, 426416,\n",
    "    572109, 258753, 662320, 328146, 354340,\n",
    "    436079, 305907, 136221, 274935,\n",
    "    733396, 258537, 434459, 738189, 280065, 834824, 175610,\n",
    "    727755,\n",
    "    1240792, 239854,\n",
    "    1209937, 1500022, 1127946, 635129, 487153, 1081115,\n",
    "    1881727,\n",
    "    206745, 118247,\n",
    "    1069583, 1368136, 437162, 522357, 742074,\n",
    "    379464, 458253,\n",
    "    582973, 331832, 660747, 464076, 878210, 1007540, 410988, 658407, 582679, 477550,\n",
    "    201004, 403118,\n",
    "    124573, 295809,\n",
    "    1078404, 786023, 453584, 1300361, 455535,\n",
    "    285616, 490493,\n",
    "    813188, 783167, 1432189, 403774, 411795, 379706,\n",
    "    362275, 386555,\n",
    "    356747, 257011,\n",
    "    454606, 350317,\n",
    "    852576, 656857, 624019, 633124, 776690, 375538, 1707996,\n",
    "    787681, 300009, 315460, 1953986, 414429, 508024, 1039926, 2494512, 274056, 667998, 1021615\n",
    "])\n",
    "\n",
    "poverty_rate_ordered = np.array([4.17,\n",
    "7.34,\n",
    "6.92,\n",
    "6.92,\n",
    "13.38,\n",
    "7.04,\n",
    "12.12,\n",
    "16.64,\n",
    "18.78,\n",
    "2.30,\n",
    "5.85,\n",
    "2.68,\n",
    "4.47,\n",
    "4.70,\n",
    "4.32,\n",
    "4.27,\n",
    "3.98,\n",
    "8.68,\n",
    "9.27,\n",
    "4.85,\n",
    "6.20,\n",
    "2.57,\n",
    "6.93,\n",
    "5.89,\n",
    "14.04,\n",
    "11.29,\n",
    "17.51,\n",
    "4.68,\n",
    "4.20,\n",
    "6.78,\n",
    "3.10,\n",
    "4.09,\n",
    "17.48,\n",
    "5.64,\n",
    "8.24,\n",
    "4.43,\n",
    "9.79,\n",
    "2.30,\n",
    "2.30,\n",
    "4.93,\n",
    "4.10,\n",
    "7.27,\n",
    "6.67,\n",
    "7.42,\n",
    "10.22,\n",
    "4.66,\n",
    "11.20,\n",
    "9.16,\n",
    "2.38,\n",
    "9.77,\n",
    "12.13,\n",
    "7.87,\n",
    "12.12,\n",
    "11.21,\n",
    "8.98,\n",
    "8.46,\n",
    "9.52,\n",
    "7.01,\n",
    "7.50,\n",
    "9.36,\n",
    "10.28,\n",
    "11.53,\n",
    "10.52,\n",
    "14.90,\n",
    "12.53,\n",
    "8.92,\n",
    "11.49,\n",
    "9.81,\n",
    "15.78,\n",
    "10.99,\n",
    "12.01,\n",
    "11.72,\n",
    "6.61,\n",
    "9.79,\n",
    "16.34,\n",
    "9.39,\n",
    "12.28,\n",
    "7.24,\n",
    "10.96,\n",
    "9.31,\n",
    "9.67,\n",
    "6.81,\n",
    "15.03,\n",
    "14.99,\n",
    "11.33,\n",
    "14.17,\n",
    "7.17,\n",
    "4.23,\n",
    "12.87,\n",
    "7.58,\n",
    "8.44,\n",
    "7.30,\n",
    "9.26,\n",
    "10.94,\n",
    "15.58,\n",
    "19.35,\n",
    "7.34,\n",
    "3.31,\n",
    "8.69,\n",
    "7.30,\n",
    "12.18,\n",
    "13.34,\n",
    "10.96,\n",
    "9.51,\n",
    "9.15,\n",
    "10.72,\n",
    "7.15,\n",
    "12.42,\n",
    "8.93,\n",
    "11.04,\n",
    "4.74,\n",
    "9.80,\n",
    "9.45,\n",
    "4.26,\n",
    "9.80,\n",
    "10.89,\n",
    "14.40,\n",
    "13.65,\n",
    "13.85,\n",
    "9.24,\n",
    "9.53,\n",
    "17.19,\n",
    "6.48,\n",
    "21.76,\n",
    "5.00,\n",
    "11.90,\n",
    "18.70,\n",
    "4.65,\n",
    "10.63,\n",
    "14.91,\n",
    "6.53,\n",
    "9.25,\n",
    "4.23,\n",
    "5.21,\n",
    "7.08,\n",
    "4.79,\n",
    "8.18,\n",
    "2.44,\n",
    "3.92,\n",
    "4.63,\n",
    "4.12,\n",
    "3.73,\n",
    "5.69,\n",
    "3.44,\n",
    "4.58,\n",
    "4.18,\n",
    "2.31,\n",
    "5.54,\n",
    "9.06,\n",
    "7.61,\n",
    "9.11,\n",
    "4.81,\n",
    "9.72,\n",
    "6.10,\n",
    "5.02,\n",
    "7.95,\n",
    "7.77,\n",
    "10.65,\n",
    "13.80,\n",
    "17.17,\n",
    "12.89,\n",
    "12.79,\n",
    "5.25,\n",
    "3.39,\n",
    "6.35,\n",
    "12.93,\n",
    "15.63,\n",
    "8.62,\n",
    "13.91,\n",
    "13.67,\n",
    "21.78,\n",
    "8.61,\n",
    "6.31,\n",
    "3.21,\n",
    "5.64,\n",
    "6.06,\n",
    "7.04,\n",
    "3.16,\n",
    "8.15,\n",
    "7.07,\n",
    "9.72,\n",
    "5.23,\n",
    "11.45,\n",
    "10.50,\n",
    "26.88,\n",
    "14.41,\n",
    "11.96,\n",
    "15.60,\n",
    "15.64,\n",
    "7.52,\n",
    "6.49,\n",
    "7.57,\n",
    "16.08,\n",
    "10.53,\n",
    "7.42,\n",
    "5.07,\n",
    "9.65,\n",
    "8.90,\n",
    "6.73,\n",
    "6.94,\n",
    "6.56,\n",
    "4.59,\n",
    "13.02,\n",
    "5.79,\n",
    "6.87,\n",
    "9.58,\n",
    "9.99,\n",
    "10.93,\n",
    "14.90,\n",
    "13.15,\n",
    "11.46,\n",
    "10.22,\n",
    "8.21,\n",
    "4.79,\n",
    "7.47,\n",
    "3.44,\n",
    "7.98,\n",
    "7.99,\n",
    "9.23,\n",
    "8.00,\n",
    "7.24,\n",
    "7.44,\n",
    "7.87])\n",
    "np_poverty_rate = np.array([])\n",
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = np.percentile(population_data_per_regency_ordered, 25)\n",
    "Q3 = np.percentile(population_data_per_regency_ordered, 75)\n",
    "# Create a DataFrame for the regencies data\n",
    "regencies_df = pd.DataFrame(regencies.items(), columns=['Regency', 'Code'])\n",
    "\n",
    "# Add a new column for population using the ordered population data\n",
    "regencies_df['Population'] = population_data_per_regency_ordered\n",
    "regencies_df['Poorness'] = poverty_rate_ordered\n",
    "\n",
    "# Display the merged DataFrame\n",
    "file_path = r'path'\n",
    "regencies_df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "subset = regencies_df.iloc[108:110]\n",
    "\n",
    "# Calculate the sum of 'Population'\n",
    "total_population = subset['Population'].sum()\n",
    "\n",
    "# Calculate the mean of 'Poorness'\n",
    "average_poorness = subset['Poorness'].mean()\n",
    "merged_data = pd.DataFrame({\n",
    "    'Regency': ['North Sulawesi'],\n",
    "    'Population': [total_population],\n",
    "    'Poorness': [average_poorness]\n",
    "})\n",
    "# Drop the first four entries from the original DataFrame\n",
    "regencies_df = regencies_df.drop(regencies_df.index[108:110])\n",
    "\n",
    "# Append the new merged entry to the DataFrame\n",
    "regencies_df = pd.concat([regencies_df, merged_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "json_data = '''\n",
    "{\n",
    "  \"age_groups\": {\n",
    "    \"0-17\": {\n",
    "      \"male\": 40761641,\n",
    "      \"female\": 38733246\n",
    "    },\n",
    "    \"17-24\": {\n",
    "      \"male\": 16126279,\n",
    "      \"female\": 15229560\n",
    "    },\n",
    "    \"25-34\": {\n",
    "      \"male\": 22701192,\n",
    "      \"female\": 21829343\n",
    "    },\n",
    "    \"35-44\": {\n",
    "      \"male\": 20950365,\n",
    "      \"female\": 20592800\n",
    "    },\n",
    "    \"45-54\": {\n",
    "      \"male\": 17619182,\n",
    "      \"female\": 17608340\n",
    "    },\n",
    "    \"55+\": {\n",
    "      \"male\": 21230173,\n",
    "      \"female\": 22391556\n",
    "    }\n",
    "  },\n",
    "  \"tiktok_users\": {\n",
    "    \"17-24\": {\n",
    "      \"male\": 25750500,\n",
    "      \"female\": 24601500\n",
    "    },\n",
    "    \"25-34\": {\n",
    "      \"male\": 27808500,\n",
    "      \"female\": 20821500\n",
    "    },\n",
    "    \"35-44\": {\n",
    "      \"male\": 10308500,\n",
    "      \"female\": 8502500\n",
    "    },\n",
    "    \"45-54\": {\n",
    "      \"male\": 4136000,\n",
    "      \"female\": 3146000\n",
    "    },\n",
    "    \"55+\": {\n",
    "      \"male\": 2638500,\n",
    "      \"female\": 2135500\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse JSON data\n",
    "data = json.loads(json_data)\n",
    "# Extract data\n",
    "categories = list(data[\"age_groups\"].keys())\n",
    "male_population = [data[\"age_groups\"][age][\"male\"] for age in categories]\n",
    "female_population = [data[\"age_groups\"][age][\"female\"] for age in categories]\n",
    "\n",
    "# TikTok user data\n",
    "male_tiktok_users = [data[\"tiktok_users\"][age][\"male\"] if age in data[\"tiktok_users\"] else 0 for age in categories]\n",
    "female_tiktok_users = [data[\"tiktok_users\"][age][\"female\"] if age in data[\"tiktok_users\"] else 0 for age in categories]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(categories, male_population, color='#3b7fb9', label='Male Population')\n",
    "ax.bar(categories, [-x for x in female_population], color='#c24837', label='Female Population')\n",
    "\n",
    "ax.bar(categories, male_tiktok_users, color='#2f6694', label='Male TikTok Users', alpha=0.5)\n",
    "ax.bar(categories, [-x for x in female_tiktok_users], color='#a63d2f', label='Female TikTok Users', alpha=0.5)\n",
    "\n",
    "# Add lines to the plot\n",
    "ax.plot(categories, male_population, marker='o', color='#e21717', linestyle='-', linewidth=1, markersize=5, label = \"Male Population\")\n",
    "ax.plot(categories, [-x for x in female_population], marker='o', color='#e21717', linestyle='-', linewidth=1, markersize=5,label = \"Female Population\")\n",
    "ax.plot(categories, male_tiktok_users, marker='o', color='#0b1925', linestyle='-', linewidth=1, markersize=5, label = \"Male User\")\n",
    "ax.plot(categories, [-x for x in female_tiktok_users], marker='o', color='#37140f', linestyle='-', linewidth=1, markersize=5, label = \"Female User\")\n",
    "\n",
    "# Customize graph (optional)\n",
    "plt.title(\"Population and TikTok Users by Age and Gender\")\n",
    "plt.xlabel(\"Age Groups\")\n",
    "plt.ylabel(\"Population / TikTok Users in Million\")\n",
    "plt.legend(loc='lower right', prop={'size': 5})  # Set the legend position to 'lower right' and font size to 8\n",
    "\n",
    "# Bolden x-axis labels\n",
    "plt.xticks(fontweight='bold')\n",
    "\n",
    "# Show or save the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TIKTOK INTEREST ##\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the categories and their respective ranges\n",
    "categories = [\n",
    "    \"Education\", \"Vehicle\", \"Baby and Kids\", \"Financial Service\", \"Beauty and Personal Care\",\n",
    "    \"Tech and Electronics\", \"Appliances\", \"Travel\", \"Household Products\", \"Pets\",\n",
    "    \"Apps\", \"Home Improvement\", \"Apparel and Accesories\", \"News and Entertainment\",\n",
    "    \"Business Service\", \"Games\", \"Life Services\", \"Food and Beveraages\", \"Sport and Outdoors\",\n",
    "    \"E-commerce (non app)\"\n",
    "]\n",
    "\n",
    "category_ranges = {\n",
    "    \"Education\": (94262000, 115210000),\n",
    "    \"Vehicle\": (87984000, 107537000),\n",
    "    \"Baby and Kids\": (89373000, 109235000),\n",
    "    \"Financial Service\": (56547000, 69114000),\n",
    "    \"Beauty and Personal Care\": (91215000, 111486000),\n",
    "    \"Tech and Electronics\": (85653000, 104688000),\n",
    "    \"Appliances\": (83165000, 101648000),\n",
    "    \"Travel\": (82171000, 100433000),\n",
    "    \"Household Products\": (84246000, 102969000),\n",
    "    \"Pets\": (89592000, 109502000),\n",
    "    \"Apps\": (90843000, 111031000),\n",
    "    \"Home Improvement\": (76911000, 94004000),\n",
    "    \"Apparel and Accesories\": (91042000, 111275000),\n",
    "    \"News and Entertainment\": (91190000, 111456000),\n",
    "    \"Business Service\": (87038000, 106381000),\n",
    "    \"Games\": (97161000, 118753000),\n",
    "    \"Life Services\": (87717000, 107211000),\n",
    "    \"Food and Beveraages\": (88993000, 108771000),\n",
    "    \"Sport and Outdoors\": (85735000, 104788000),\n",
    "    \"E-commerce (non app)\": (66242000, 80964000)\n",
    "}\n",
    "\n",
    "# Calculate the proportion of each category relative to the total number of general users\n",
    "total_general_users = (103959000 + 127062000) / 2  # Taking average of the range\n",
    "\n",
    "category_proportions = {}\n",
    "for category, (min_val, max_val) in category_ranges.items():\n",
    "    category_proportions[category] = ((min_val + max_val) / 2) / total_general_users\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame.from_dict(category_proportions, orient='index', columns=['Proportion'])\n",
    "df = df.sort_values(by='Proportion', ascending=False)\n",
    "\n",
    "# Plot the diagram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df.index, df['Proportion'], color='skyblue')\n",
    "plt.xlabel('Proportion of Users')\n",
    "plt.ylabel('Categories')\n",
    "plt.title('Normalized Proportion of Users by Category')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest proportion at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGE GROUPS ACROSS REGENCIES WITH EDUCATION INTEREST ###\n",
    "result_df_age_group_edu = pd.DataFrame(columns=['Location', 'Age Group', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in provinces.items():\n",
    "    for age_group in age_groups:\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID=location_value, ageList= age_group)\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        # Append the result to the DataFrame\n",
    "        df_temp = pd.DataFrame({'Location': location_key, 'Age Group': f'{age_group[0]}-{age_group[1]}', 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        result_df_age_group_edu = pd.concat([result_df_age_group_edu, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONNECTION TYPE EDUCATIONAAL CONTENT ## \n",
    "connection_type = {\n",
    "    'Wi-Fi': [\"1\"],\n",
    "    '2G': [\"2\"],\n",
    "    '4G': [\"4\"],\n",
    "}\n",
    "result_df_connection_type_edu = pd.DataFrame(columns=['Location','Connection Type', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in provinces.items():\n",
    "    for connection_key , connection_value in connection_type.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID= location_value,  connectionType= connection_value)\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        # Append the result to the DataFrame\n",
    "        df_temp = pd.DataFrame({'Location': location_key,'Connection Type': connection_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        result_df_connection_type_edu = pd.concat([result_df_connection_type_edu, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_df = pd.DataFrame()\n",
    "\n",
    "# Merging Gender data\n",
    "gender_df = result_df_gender_education_provinces.pivot(index='Location', columns='Gender', values='Average').reset_index()\n",
    "province_df = gender_df\n",
    "\n",
    "# Merging Age Group data\n",
    "age_group_df = result_df_age_group_edu.pivot(index='Location', columns='Age Group', values='Average').reset_index()\n",
    "province_df = pd.merge(province_df, age_group_df, on='Location', how='outer')\n",
    "\n",
    "# Merging Connection Type data\n",
    "connection_type_df = result_df_connection_type_edu.pivot(index='Location', columns='Connection Type', values='Average').reset_index()\n",
    "province_df = pd.merge(province_df, connection_type_df, on='Location', how='outer')\n",
    "completion_rates = [\n",
    "    74.46, 76.51, 68.96, 70.07, 63.41, 58.35, 63.93, 55.69, 68.65, 73.63, \n",
    "    43.46, 46.19, 88.1, 66.62, 64.54, 75.01, 59.5, 64.61, 67.57, 74.43, \n",
    "    39.5, 67.79, 78.97, 68.35, 67.41, 64.81, 68.28, 66.47, 55.58, 63.66, \n",
    "    59.99, 54.79, 68.64, 89.69\n",
    "]\n",
    "\n",
    "poor_population_percentage = [\n",
    "    14.45, 4.25, 4.52, 6.17, 14.04, 10.77, 5.11, 12.41, 10.35, 6.11, \n",
    "    19.96, 15.15, 4.44, 7.58, 11.11, 16.42, 6.45, 6.46, 7.38, 8.15, \n",
    "    26.03, 6.68, 5.69, 4.29, 8.7, 11.78, 11.43, 7.62, 6.71, 13.85, \n",
    "    20.49, 11.49, 5.95, 11.04\n",
    "]\n",
    "province_df['High School Completion Rate'] = completion_rates\n",
    "province_df['Poor Population Percentage'] = poor_population_percentage\n",
    "print(province_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_connection_type_edu\n",
    "file_path = r'D:\\Thesis\\data\\result_df_connection_type_edu.txt'\n",
    "result_df_connection_type_edu.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_language_edu = pd.DataFrame(columns=['Location', 'Language', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for language_key , language_value in language_content.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID= location_value, LanguageList= language_value)\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        # Append the result to the DataFrame\n",
    "        df_temp = pd.DataFrame({'Location': location_key, 'Language': language_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        result_df_language_edu = pd.concat([result_df_language_edu, df_temp], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_audience_normal = pd.DataFrame(columns=['Location' , 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in provinces.items():\n",
    "    response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID=location_value)\n",
    "    upper, lower = get_upper_lower(response_content)\n",
    "    df_temp = pd.DataFrame({'Location': location_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "    prov_audience_normal = pd.concat([prov_audience_normal, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "# DATA FOR USER INTERESTED IN EDUCATION PER PROVINCE #\n",
    "data_updated = {\n",
    "    \"Location\": [\n",
    "        \"ACEH\", \"BALI\", \"BANTEN\", \"BENGKULU\",\"DKI JAKARTA\", \"GORONTALO\", \"JAMBI\", \"JAWA BARAT\", \"JAWA TENGAH\",\n",
    "\"JAWA TIMUR\", \"KALIMANTAN BARAT\", \"KALIMANTAN SELATAN\", \"KALIMANTAN TENGAH\", \"KALIMANTAN TIMUR\",\n",
    "\"KALIMANTAN UTARA\", \"KEPULAUAN BANGKA BELITUNG\", \"KEPULAUAN RIAU\", \"LAMPUNG\", \"MALUKU\", \"MALUKU UTARA\",\n",
    "\"NUSA TENGGARA BARAT\", \"NUSA TENGGARA TIMUR\", \"PAPUA\", \"PAPUA BARAT\", \"RIAU\", \"SULAWESI BARAT\",\n",
    "\"SULAWESI SELATAN\", \"SULAWESI TENGAH\", \"SULAWESI TENGGARA\", \"SULAWESI UTARA\", \"SUMATERA BARAT\",\n",
    "\"SUMATERA SELATAN\", \"SUMATERA UTARA\", \"YOGYAKARTA\"\n",
    "    ],\n",
    "    \"Gender\": [\"All\"] * 34,\n",
    "    \"Lower Value\": [\n",
    "        1866000, 2727000, 6099000, 659000, 6093000, 479000, 1578000, 24380000, 13603000, 17723000, 2190000,\n",
    "        2246000, 1279000, 2622000, 311000, 303000, 1472000, 3069000, 551000, 405000, 1404000, 1013000, 720000,\n",
    "        452000, 3788000, 204000, 4620000, 1051000, 847000, 1291000, 2232000, 3572000, 6063000, 1641000\n",
    "    ],\n",
    "    \"Upper Value\": [\n",
    "        1526000, 2230000, 4989000, 539000, 4985000, 391000, 1290000, 19947000, 11128000, 14499000, 1791000,\n",
    "        1837000, 1045000, 2144000, 254000, 247000, 1203000, 2511000, 450000, 331000, 1148000, 828000, 588000,\n",
    "        369000, 3099000, 166000, 3779000, 859000, 692000, 1056000, 1825000, 2922000, 4960000, 1342000\n",
    "    ]\n",
    "}\n",
    "educational_levels_seniorhigh = {\n",
    "    \"ACEH\": 70.67,\n",
    "    \"SUMATERA UTARA\": 77.16,\n",
    "    \"SUMATERA BARAT\": 65.96,\n",
    "    \"RIAU\": 66.91,\n",
    "    \"JAMBI\": 65.85,\n",
    "    \"SUMATERA SELATAN\": 67.07,\n",
    "    \"BENGKULU\": 64.88,\n",
    "    \"LAMPUNG\": 62.42,\n",
    "    \"KEP. BANGKA BELITUNG\": 66.87,\n",
    "    \"KEP. RIAU\": 73.93,\n",
    "    \"DKI JAKARTA\": 87.71,\n",
    "    \"JAWA BARAT\": 67.05,\n",
    "    \"JAWA TENGAH\": 58.75,\n",
    "    \"DI YOGYAKARTA\": 87.92,\n",
    "    \"JAWA TIMUR\": 66.87,\n",
    "    \"BANTEN\": 66.02,\n",
    "    \"BALI\": 76.59,\n",
    "    \"NUSA TENGGARA BARAT\": 61.0,\n",
    "    \"NUSA TENGGARA TIMUR\": 38.47,\n",
    "    \"KALIMANTAN BARAT\": 58.4,\n",
    "    \"KALIMANTAN TENGAH\": 61.88,\n",
    "    \"KALIMANTAN SELATAN\": 67.81,\n",
    "    \"KALIMANTAN TIMUR\": 74.0,\n",
    "    \"KALIMANTAN UTARA\": 54.8,\n",
    "    \"SULAWESI UTARA\": 66.66,\n",
    "    \"SULAWESI TENGAH\": 53.73,\n",
    "    \"SULAWESI SELATAN\": 68.32,\n",
    "    \"SULAWESI TENGGARA\": 65.97,\n",
    "    \"GORONTALO\": 45.12,\n",
    "    \"SULAWESI BARAT\": 55.18,\n",
    "    \"MALUKU\": 72.08,\n",
    "    \"MALUKU UTARA\": 67.1,\n",
    "    \"PAPUA BARAT\": 57.07,\n",
    "    \"PAPUA\": 39.01\n",
    "}\n",
    "\n",
    "educational_levels_junior = {\n",
    "    \"ACEH\": 94.55,\n",
    "    \"SUMATERA UTARA\": 94.35,\n",
    "    \"SUMATERA BARAT\": 90.65,\n",
    "    \"RIAU\": 90.52,\n",
    "    \"JAMBI\": 89.35,\n",
    "    \"SUMATERA SELATAN\": 87.95,\n",
    "    \"BENGKULU\": 89.25,\n",
    "    \"LAMPUNG\": 87.67,\n",
    "    \"KEP. BANGKA BELITUNG\": 87.11,\n",
    "    \"KEP. RIAU\": 95.51,\n",
    "    \"DKI JAKARTA\": 95.85,\n",
    "    \"JAWA BARAT\": 91.42,\n",
    "    \"JAWA TENGAH\": 90.64,\n",
    "    \"DI YOGYAKARTA\": 97.02,\n",
    "    \"JAWA TIMUR\": 90.74,\n",
    "    \"BANTEN\": 90.86,\n",
    "    \"BALI\": 93.03,\n",
    "    \"NUSA TENGGARA BARAT\": 92.95,\n",
    "    \"NUSA TENGGARA TIMUR\": 82.48,\n",
    "    \"KALIMANTAN BARAT\": 81.56,\n",
    "    \"KALIMANTAN TENGAH\": 88.92,\n",
    "    \"KALIMANTAN SELATAN\": 88.19,\n",
    "    \"KALIMANTAN TIMUR\": 94.85,\n",
    "    \"KALIMANTAN UTARA\": 88.08,\n",
    "    \"SULAWESI UTARA\": 92.07,\n",
    "    \"SULAWESI TENGAH\": 90.05,\n",
    "    \"SULAWESI SELATAN\": 88.74,\n",
    "    \"SULAWESI TENGGARA\": 89.55,\n",
    "    \"GORONTALO\": 83.71,\n",
    "    \"SULAWESI BARAT\": 84.04,\n",
    "    \"MALUKU\": 93.9,\n",
    "    \"MALUKU UTARA\": 93.46,\n",
    "    \"PAPUA BARAT\": 88.63,\n",
    "    \"PAPUA\": 67.12\n",
    "}\n",
    "\n",
    "educational_levels_elementary = {\n",
    "    \"ACEH\": 99.08,\n",
    "    \"SUMATERA UTARA\": 98.75,\n",
    "    \"SUMATERA BARAT\": 95.81,\n",
    "    \"RIAU\": 98.09,\n",
    "    \"JAMBI\": 97.76,\n",
    "    \"SUMATERA SELATAN\": 97.58,\n",
    "    \"BENGKULU\": 97.1,\n",
    "    \"LAMPUNG\": 98.67,\n",
    "    \"KEP. BANGKA BELITUNG\": 96.01,\n",
    "    \"KEP. RIAU\": 97.92,\n",
    "    \"DKI JAKARTA\": 98.66,\n",
    "    \"JAWA BARAT\": 99.09,\n",
    "    \"JAWA TENGAH\": 98.42,\n",
    "    \"DI YOGYAKARTA\": 98.95,\n",
    "    \"JAWA TIMUR\": 98.78,\n",
    "    \"BANTEN\": 97.15,\n",
    "    \"BALI\": 98.43,\n",
    "    \"NUSA TENGGARA BARAT\": 98.11,\n",
    "    \"NUSA TENGGARA TIMUR\": 93.41,\n",
    "    \"KALIMANTAN BARAT\": 95.33,\n",
    "    \"KALIMANTAN TENGAH\": 97.47,\n",
    "    \"KALIMANTAN SELATAN\": 95.99,\n",
    "    \"KALIMANTAN TIMUR\": 97.88,\n",
    "    \"KALIMANTAN UTARA\": 96.41,\n",
    "    \"SULAWESI UTARA\": 96.18,\n",
    "    \"SULAWESI TENGAH\": 97.56,\n",
    "    \"SULAWESI SELATAN\": 98.37,\n",
    "    \"SULAWESI TENGGARA\": 97.83,\n",
    "    \"GORONTALO\": 93.69,\n",
    "    \"SULAWESI BARAT\": 95.13,\n",
    "    \"MALUKU\": 98.69,\n",
    "    \"MALUKU UTARA\": 98.3,\n",
    "    \"PAPUA BARAT\": 92.69,\n",
    "    \"PAPUA\": 80.09\n",
    "}\n",
    "user_normalized_by_population_provinces = {\n",
    "  \"ACEH\": 0.3136152665544851,\n",
    "  \"SUMATERA UTARA\": 0.3646329522599767,\n",
    "  \"SUMATERA BARAT\": 0.3596248626032692,\n",
    "  \"RIAU\": 0.5206065553942912,\n",
    "  \"KEP. RIAU\": 0.6135884026057436,\n",
    "  \"JAMBI\": 0.3949216490870535,\n",
    "  \"SUMATERA SELATAN\": 0.3750721959108236,\n",
    "  \"KEP. BANGKA BELITUNG\": 0.1839957179178375,\n",
    "  \"BENGKULU\": 0.290762584340566,\n",
    "  \"LAMPUNG\": 0.3040341738770351,\n",
    "  \"DKI JAKARTA\": 0.5186329588014981,\n",
    "  \"JAWA BARAT\": 0.4486011763801011,\n",
    "  \"BANTEN\": 0.4524975514201763,\n",
    "  \"JAWA TENGAH\": 0.3339103055702574,\n",
    "  \"DI YOGYAKARTA\": 0.3964751854116271,\n",
    "  \"JAWA TIMUR\": 0.3915188335358445,\n",
    "  \"KALIMANTAN BARAT\": 0.3592052549897138,\n",
    "  \"KALIMANTAN TENGAH\": 0.4239174054211813,\n",
    "  \"KALIMANTAN SELATAN\": 0.4881518854164176,\n",
    "  \"KALIMANTAN TIMUR\": 0.6173895020467382,\n",
    "  \"KALIMANTAN UTARA\": 0.3881560868370431,\n",
    "  \"SULAWESI UTARA\": 0.4412483549539387,\n",
    "  \"GORONTALO\": 0.3647187054582041,\n",
    "  \"SULAWESI TENGAH\": 0.3114705978278595,\n",
    "  \"SULAWESI SELATAN\": 0.4551908777558586,\n",
    "  \"SULAWESI BARAT\": 0.1268339503633621,\n",
    "  \"SULAWESI TENGGARA\": 0.2848206684680016,\n",
    "  \"BALI\": 0.5613689384158909,\n",
    "  \"NUSA TENGGARA BARAT\": 0.2331147121690995,\n",
    "  \"NUSA TENGGARA TIMUR\": 0.1683954411576386,\n",
    "  \"MALUKU\": 0.2659828878142106,\n",
    "  \"MALUKU UTARA\": 0.2789357992875009,\n",
    "  \"PAPUA BARAT\": 0.3469111805966365,\n",
    "  \"PAPUA\": 0.1480106821165075\n",
    "}\n",
    "province_names = list(user_normalized_by_population_provinces.keys())\n",
    "user_interest_normalized = np.array(list(user_normalized_by_population_provinces.values()))\n",
    "educational_levels = np.array([educational_levels_seniorhigh[province] for province in province_names])\n",
    "\n",
    "# Fit a polynomial regression model with degree 2\n",
    "degree = 2 # Set the degree of the polynomial\n",
    "coefficients = np.polyfit(educational_levels, user_interest_normalized, degree)\n",
    "\n",
    "# Generate polynomial function using the coefficients\n",
    "poly_function = np.poly1d(coefficients)\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_values = np.linspace(min(educational_levels), max(educational_levels), 100)\n",
    "\n",
    "# Calculate predicted y values using the polynomial function\n",
    "y_values = poly_function(x_values)\n",
    "\n",
    "# Plot the data points and the polynomial regression curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(educational_levels, user_interest_normalized, label='Data Points', color='blue')\n",
    "plt.plot(x_values, y_values, color='red', label='Polynomial Regression (Degree {})'.format(degree))\n",
    "plt.title('Educational Levels vs. TikTok User Interest')\n",
    "plt.xlabel('Percentage of People Finished Senior High School')\n",
    "plt.ylabel('TikTok User Interest (Normalized by Population)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(poly_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TIKTOK INTEREST ON EDUCATIONAL CONTENT BY AD_TAG_V2\"\n",
    "\n",
    "interest = {\n",
    "    'Early Childhood & Preschool Education': 10100,\n",
    "    'Primary & Secondary Education & K-12': 10101,\n",
    "    'Higher Education - Adult Education': 10102100,\n",
    "    'Higher Education - College Education': 10102101,\n",
    "    'Overseas Education - Overseas Study for Undergraduate Education': 10103101,\n",
    "    'Overseas Education - ESL Training': 10103103,\n",
    "    'Vocational Training - IT Training & Examinations': 10104100,\n",
    "    'Vocational Training - Design Training & Education': 10104101,\n",
    "    'Vocational Training - Chef Training & Examinations': 10104103,\n",
    "    'Vocational Training - Enterprise Management Training': 10104104,\n",
    "    'Vocational Training - Medical Licensing Training & Examinations': 10104105,\n",
    "    'Vocational Training - Beauty Education': 10104108,\n",
    "    'Vocational Training - Driving Schools & Pilot Training': 10104109,\n",
    "    'Vocational Training - Marketing Management Education': 10104112,\n",
    "    'English Language': 10105101,\n",
    "    'Spanish Language': 10105104,\n",
    "    'Music & Instruments': 10106100,\n",
    "    'Calligraphy & Art': 10106101,\n",
    "    'Sports': 10106103,\n",
    "    'Vehicle': 11\n",
    "}\n",
    "\n",
    "\n",
    "result_df_interest = pd.DataFrame(columns=['Location', 'Interest', 'Lower Value', 'Upper Value'])\n",
    "for gender_key, gender_value in gender.items():\n",
    "    for interest_key , interest_value in interest.items():\n",
    "        Json_Data['audience']['ad_tag_v2'] = interest_value\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, gender_value, interest_value)\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        # Append the result to the DataFrame\n",
    "        df_temp = pd.DataFrame({'Location': 'Indonesia', 'Gender': gender_key, 'Interest': interest_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        result_df_interest = pd.concat([result_df_interest, df_temp], ignore_index=True)\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device_group = {'Android' : '1' , 'iOs' : '2'}\n",
    "\n",
    "result_df_device_edu = pd.DataFrame(columns=['Location', 'Device', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in provinces.items():\n",
    "    for device_key, device_value in device_group.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID= location_value,device=device_value)\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location': location_key , 'Device': device_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        result_df_device_edu = pd.concat([result_df_device_edu, df_temp], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_device_edu[\"Average\"] = (result_df_device_edu[\"Upper Value\"] +result_df_device_edu[\"Lower Value\"] )/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_device_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r'D:\\Thesis\\result_df_device_edu.txt'\n",
    "## result_df_device_age_regency.to_csv(file_path, sep='\\t', index=False)\n",
    "result_df_device_edu = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:\\Thesis\\data\\result_df_device_edu.txt'\n",
    "result_df_device_edu.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_age_group_edu['Average'] = (result_df_age_group_edu['Lower Value'] + result_df_age_group_edu['Upper Value']) / 2\n",
    "result_df_age_group_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = {\n",
    "    \"#general_education\": [1451574786550,562644897394,1072966995653,1148464905382,2060968049509,1333928306370]\n",
    "}\n",
    "business_finance = {\n",
    "    \"#business_finance\": [1149445381426,1967215180426,2675556295657]\n",
    "}\n",
    "life_skills = {\n",
    "    \"#life_skills\": [136867601338,1457946270310,1517403240353,3241564962898,3527264231561,1024133548193]\n",
    "}\n",
    "academic_subjects = {\n",
    "    \"#academic_subject\": [3511430817153,3931938773594,4263543489876]\n",
    "}\n",
    "language = {\n",
    "    \"#language\":[83482039010,969069382560,1221589859329,1820863810266,1900188677257,2614601015417,2998469186349]\n",
    "}\n",
    "art = {\n",
    "    \"#art\": [2979160688042,3750411512762,2124935966250,582977008337]\n",
    "}\n",
    "\n",
    "\n",
    "all_educational_hashtag ={ \"#Educational_Hashtag\" : [1451574786550,562644897394,1072966995653,1148464905382,2060968049509,1333928306370,1149445381426,1967215180426,2675556295657,83482039010,969069382560,1221589859329,1820863810266,1900188677257,2614601015417,2998469186349,2979160688042,3750411512762,2124935966250,582977008337,3511430817153,3931938773594,4263543489876,136867601338,1457946270310,1517403240353,3241564962898,3527264231561,1024133548193]\n",
    "\n",
    "}\n",
    "\n",
    "travel = {\n",
    "    \"#travel\" : [318157865682,844717160540,1083648577289,1139161085963,1401198526418,2923881170595,3777985416715]\n",
    "}\n",
    "shopping = {\n",
    "    \"#shopping\" : [787720117666,1193112582954,1367411408594,2001469755470,2453143311250,2458958956905,3105050594738,3113363306521,3259768241920,3262784422352,3867826421305,3526749516170,4071395951009,4215695503674]\n",
    "}\n",
    "\n",
    "eat = {\n",
    "    \"#eat\" : [83896211476, 93355400225, 161112525422, 441858503268, 520815044153, 644441631131, 667947783040, 702532510145, 742174441621, 744198620337, 849476447945, 968220878434, 1103321395241, 1317452898458, 1326585611593, 1343079744810, 1379923094473, 1395832910729, 1607611334823, 1669254618601, 1733081256803, 1782153230006, 1812708915618, 1923180834185, 1937181640792, 1942693097154, 2011407829250, 2084685440415, 2142399661201, 2309004353911, 2329161585106, 2460808230513, 2685197866377, 2759729368745, 2919257768172, 3015893876601, 3087002611730, 3160543582307, 3433337070234, 3436560692338, 3452059310643, 3493453922705, 3586941272881, 3621943498712, 3645580963834, 3732245987298, 3900868004729, 3963514183377, 4257326606098, 4274032658814, 4276615760044, 4287206236666]\n",
    "\n",
    "}\n",
    "\n",
    "sport = {\n",
    "    \"#sport\" : [128709844241, 262010197226, 360270673825, 621802358337, 656984979161, 726261401059, 965489298921, 1109604396994, 1146289860602, 1519118946468, 1824234296977, 1976580633570, 2210445263834, 2808318706402, 3142853836793, 3227398535600]\n",
    "\n",
    "}\n",
    "\n",
    "gaming = {\n",
    "    \"#gaming\" : [236993399279, 9973815578, 102258843098, 231995504590, 240610373674, 285623601637, 286841887390, 309839568709, 331499837396, 360173135208, 471666832598, 523782567057, 643674014566, 679531769886, 802294745271, 843719131471, 953843696149, 982170129622, 985636273229, 988434470076, 1131017136001, 1150486662488, 1175347729557, 1205437547246, 1245495457187, 1248445117926, 1302107240682, 1322454945092, 1338233219134, 1400967311100, 1412802287512, 1625229720709, 1779243334574, 1917087662525, 1934174722334, 1945261543915, 1996167021670, 2014972623629, 2021667891577]\n",
    "\n",
    "}\n",
    "\n",
    "activity = {\"Hiking\" : [\n",
    "    1328708993641,\n",
    "    1841954410486,\n",
    "    955027586678,\n",
    "    2860308994773,\n",
    "    3066588375076\n",
    "] , \n",
    "            \"Camping\" : [\n",
    "    174155978898,\n",
    "    226810041283,\n",
    "    357826419628,\n",
    "    408527751570,\n",
    "    525645648040,\n",
    "    553362773469,\n",
    "    713661136575,\n",
    "    827492888058,\n",
    "    881157831901,\n",
    "    898273659712,\n",
    "    941399052518,\n",
    "    963508602861,\n",
    "    1255845685102,\n",
    "    1289920989269,\n",
    "    2037155157548,\n",
    "    2117577429009,\n",
    "    2165672414019,\n",
    "    2276635518458,\n",
    "    2989860074748,\n",
    "    3596359006474,\n",
    "    3946001375865,\n",
    "    3947938367929,\n",
    "    4252904399118,\n",
    "    278709192748,\n",
    "    1291195094550\n",
    "], \"Surfing\" :  [\n",
    "    1320846404218,\n",
    "    1343959833535,\n",
    "    1360944296908,\n",
    "    1780588995664,\n",
    "    1999070962914,\n",
    "    2047382333897,\n",
    "    3313157870125,\n",
    "    3503052716067,\n",
    "    3593934986176,\n",
    "    3764296712506\n",
    "], \"Paragliding\" : [1966092072110], \n",
    "\"Rafting\" : [\n",
    "    3862537078083,\n",
    "    1370587027236,\n",
    "    3419323832185\n",
    "], \"Snorkeling and Diving\" : [\n",
    "    185799693893,\n",
    "    649848314888,\n",
    "    2305572712967,\n",
    "    3807567392796,\n",
    "    1597759827580,\n",
    "    2570329134109,\n",
    "    3610899205760,\n",
    "    3949136318471\n",
    "], \"Rock Climbing\" : [1013074409716, 2489852386744]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_df_country_travel_audience = pd.DataFrame(columns=['Location',  'Lower Value', 'Upper Value'])\n",
    "\n",
    "for location_key, location_value in country.items():\n",
    "    for hashtag_key , hashtag_value in activity.items() :\n",
    "        for gender_key , gender_value in gender.items() :  \n",
    "            response_content, status_code = request_tiktok(cookies, headers, Json_Data, LocID = location_value, hashTagID=[hashtag_value] , GenID= gender_value )\n",
    "            uper, lower = get_upper_lower(response_content)  \n",
    "            df_temp = pd.DataFrame({'Location': location_key,'Gender' : gender_key , 'Activity': hashtag_key, 'Upper Value': uper, 'Lower Value': lower}, index=[0])\n",
    "            result_df_country_travel_audience = pd.concat([result_df_country_travel_audience, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_country_travel_audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_country_travel_audience[\"Average\"] = (result_df_country_travel_audience[\"Lower Value\"] + result_df_country_travel_audience[\"Upper Value\"]  )/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'Male': 'white', 'Female': 'pink'}\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Width of bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Positions of bars on x-axis\n",
    "index = np.arange(len(result_df_country_travel_audience['Activity'].unique()))\n",
    "\n",
    "# Creating a bar for each gender\n",
    "for i, gender in enumerate(result_df_country_travel_audience['Gender'].unique()):\n",
    "    subset = result_df_country_travel_audience[result_df_country_travel_audience['Gender'] == gender]\n",
    "    ax.bar(index + i * bar_width, subset['Average'], bar_width, label=gender, color=colors[gender], edgecolor='black')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Activity')\n",
    "ax.set_ylabel('Average Value')\n",
    "ax.set_title('Average Value by Activity and Gender in Indonesia')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(df['Activity'].unique(), rotation=45)\n",
    "ax.legend(title='Gender')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:\\Thesis\\data\\audience_data.txt'\n",
    "result_df_country_travel_audience.to_csv(file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "travel_ = pd.DataFrame(columns=['Location',\"Gender\",'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in regencies.items():\n",
    "    for gender_key , gender_value in gender.items():\n",
    "        for hashtag_key, hashtag_value in travel.items():\n",
    "            response_content, status_code = request_tiktok(cookies, headers, Json_Data, GenID=gender_value,hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "            upper, lower = get_upper_lower(response_content)\n",
    "            df_temp = pd.DataFrame({'Location' : location_key, 'Gender' : gender_key, 'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "            travel_ = pd.concat([travel_, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_ = pd.DataFrame(columns=['Location',\"Gender\",'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in regencies.items():\n",
    "    for gender_key , gender_value in gender.items():\n",
    "        for hashtag_key, hashtag_value in shopping.items():\n",
    "            response_content, status_code = request_tiktok(cookies, headers, Json_Data, GenID=gender_value,hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "            upper, lower = get_upper_lower(response_content)\n",
    "            df_temp = pd.DataFrame({'Location' : location_key, 'Gender' : gender_key, 'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "            shopping_ = pd.concat([shopping_, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eat_ = pd.DataFrame(columns=['Location',\"Gender\",'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in regencies.items():\n",
    "    for gender_key , gender_value in gender.items():\n",
    "        for hashtag_key, hashtag_value in eat.items():\n",
    "            response_content, status_code = request_tiktok(cookies, headers, Json_Data, GenID=gender_value,hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "            upper, lower = get_upper_lower(response_content)\n",
    "            df_temp = pd.DataFrame({'Location' : location_key, 'Gender' : gender_key, 'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "            eat_ = pd.concat([eat_, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gaming_ = pd.DataFrame(columns=['Location',\"Gender\",'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in regencies.items():\n",
    "    for gender_key , gender_value in gender.items():\n",
    "        for hashtag_key, hashtag_value in gaming.items():\n",
    "            response_content, status_code = request_tiktok(cookies, headers, Json_Data, GenID=gender_value,hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "            upper, lower = get_upper_lower(response_content)\n",
    "            df_temp = pd.DataFrame({'Location' : location_key, 'Gender' : gender_key, 'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "            gaming_ = pd.concat([gaming_, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_[\"Average\"] = (travel_[\"Lower Value\"] + travel_[\"Upper Value\"])/2\n",
    "gaming_[\"Average\"] = (gaming_[\"Lower Value\"] + gaming_[\"Upper Value\"])/2\n",
    "eat_[\"Average\"] = (eat_[\"Lower Value\"] + eat_[\"Upper Value\"])/2\n",
    "shopping_[\"Average\"] = (shopping_[\"Lower Value\"] + shopping_[\"Upper Value\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values = shopping_.groupby('Gender')[['Lower Value', 'Upper Value']].mean().reset_index()\n",
    "\n",
    "# Plotting the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_values['Gender'], average_values['Lower Value'], label='Lower Value', alpha=0.7)\n",
    "plt.bar(average_values['Gender'], average_values['Upper Value'], label='Upper Value', alpha=0.7, bottom=average_values['Lower Value'])\n",
    "\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Interest In Shopping')\n",
    "plt.title('Audience Interested in Shopping Content')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values_travel = travel_.groupby('Gender')[['Lower Value', 'Upper Value']].mean().reset_index()\n",
    "\n",
    "# Plotting the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_values_travel['Gender'], average_values_travel['Lower Value'], label='Lower Value', alpha=0.7)\n",
    "plt.bar(average_values_travel['Gender'], average_values_travel['Upper Value'], label='Upper Value', alpha=0.7, bottom=average_values_travel['Lower Value'])\n",
    "\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Interest In Travel')\n",
    "plt.title('Audience Interested in Traveling Content')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values_gaming = gaming_.groupby('Gender')[['Lower Value', 'Upper Value']].mean().reset_index()\n",
    "\n",
    "# Plotting the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_values_gaming['Gender'], average_values_gaming['Lower Value'], label='Lower Value', alpha=0.7)\n",
    "plt.bar(average_values_gaming['Gender'], average_values_gaming['Upper Value'], label='Upper Value', alpha=0.7, bottom=average_values_gaming['Lower Value'])\n",
    "\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Interest In Gaming')\n",
    "plt.title('Audience Interested in Gaming Content')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values_eat = eat_.groupby('Gender')[['Lower Value', 'Upper Value']].mean().reset_index()\n",
    "\n",
    "# Plotting the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_values_eat['Gender'], average_values_eat['Lower Value'], label='Lower Value', alpha=0.7)\n",
    "plt.bar(average_values_eat['Gender'], average_values_eat['Upper Value'], label='Upper Value', alpha=0.7, bottom=average_values_eat['Lower Value'])\n",
    "\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Interest In Food')\n",
    "plt.title('Audience Interested in Food Content')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df = all_hashtag_education.pivot(index='Location', columns='Hashtag', values='Average').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the population pyramid\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "age_groups = proportion_by_age_gender.index\n",
    "male_counts = -proportion_by_age_gender['Male']  # Negative for left side\n",
    "female_counts = proportion_by_age_gender['Female']\n",
    "\n",
    "ax.barh(age_groups, male_counts, color='skyblue', edgecolor='black', label='Male')\n",
    "ax.barh(age_groups, female_counts, color='lightcoral', edgecolor='black', label='Female')\n",
    "\n",
    "# Adding grid, labels, and title for better aesthetics\n",
    "ax.set_xlabel('Proportion of Total Users')\n",
    "ax.set_ylabel('Age Group')\n",
    "ax.set_title('Age-Sex Pyramid for General Education Hashtag')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Improve tick labels for readability\n",
    "ax.set_xticklabels([f'{abs(x*100):.0f}%' for x in ax.get_xticks()])\n",
    "\n",
    "# Adding central line for better readability\n",
    "plt.axvline(0, color='black', lw=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hashtag_business_finance = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in business_finance.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers,Json_Data , hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_business_finance = pd.concat([hashtag_business_finance, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_life_skills = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in life_skills.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_life_skills = pd.concat([hashtag_life_skills, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_academic_subjects = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in academic_subjects.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_academic_subjects = pd.concat([hashtag_academic_subjects, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_language = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in language.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_language = pd.concat([hashtag_language, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_art = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in art.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_art = pd.concat([hashtag_art, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_gaming = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in gaming.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_gaming = pd.concat([hashtag_gaming, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_travel = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in travel.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_travel = pd.concat([hashtag_travel, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_sport = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in sport.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_sport = pd.concat([hashtag_sport, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_eat = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in eat.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_eat = pd.concat([hashtag_eat, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_shopping = pd.DataFrame(columns=['Location', 'Hashtag', 'Lower Value', 'Upper Value'])\n",
    "for location_key, location_value in locations.items():\n",
    "    for hashtag_key, hashtag_value in shopping.items():\n",
    "        response_content, status_code = request_tiktok(cookies, headers, Json_Data, hashTagID=[hashtag_value], LocID=location_value)  # Wrap hashtag_value in a list\n",
    "        upper, lower = get_upper_lower(response_content)\n",
    "        df_temp = pd.DataFrame({'Location' : location_key,'Hashtag': hashtag_key, 'Upper Value': upper, 'Lower Value': lower}, index=[0])\n",
    "        hashtag_shopping = pd.concat([hashtag_shopping, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Category values\n",
    "categories = {\n",
    "    \"Education\": (79816000, 97554000),\n",
    "    \"Vehicle & Transportation\": (87984000, 107537000),\n",
    "    \"Baby Kids and Maternity\": (89373000, 109235000),\n",
    "    \"Financial Services\": (56547000, 69114000),\n",
    "    \"Beauty & Personal Care\": (91215000, 111486000),\n",
    "    \"Tech & Electronics\": (85653000, 104688000),\n",
    "    \"Appliances\": (83165000, 101648000),\n",
    "    \"Travel\": (82171000, 100433000),\n",
    "    \"Household Products\": (84246000, 102969000),\n",
    "    \"Pets\": (89592000, 109502000),\n",
    "    \"Apps\": (90843000, 111031000),\n",
    "    \"Home Improvement\": (76911000, 94004000),\n",
    "    \"Apparel & Accesories\": (91042000, 111275000),\n",
    "    \"News & Entertainment\": (91190000, 111456000),\n",
    "    \"Business Service\": (87038000, 106381000),\n",
    "    \"Games\": (97161000, 118753000),\n",
    "    \"Life Services\": (87717000, 107211000),\n",
    "    \"Food and Beverages\": (88993000, 108771000),\n",
    "    \"Sport and Outdoors\": (85735000, 104788000),\n",
    "    \"E-Commerce (non App)\": (66242000, 80964000)\n",
    "}\n",
    "\n",
    "# Calculate average values\n",
    "averages = {}\n",
    "for category, values in categories.items():\n",
    "    lower, upper = values\n",
    "    avg = (lower + upper) / 2\n",
    "    averages[category] = avg\n",
    "\n",
    "# \"No category\" values\n",
    "no_category_lower = 103959000\n",
    "no_category_upper = 127062000\n",
    "no_category_avg = (no_category_lower + no_category_upper) / 2\n",
    "\n",
    "# Calculate proportions based on \"no category\"\n",
    "proportions = {}\n",
    "for category, avg in averages.items():\n",
    "    proportions[category] = avg / no_category_avg\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(list(proportions.keys()), list(proportions.values()), color='skyblue')\n",
    "plt.xlabel('Proportion')\n",
    "plt.title('Proportions of Different Categories Compared to \"No Category\"')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest proportion at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Calculate Total Facebook User in Indonesia\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_facebook_users(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        total_users_span = soup.find('div', class_='visualize-stats--total')\n",
    "        if total_users_span:\n",
    "            total_users = total_users_span.get_text(strip=True)\n",
    "            return total_users\n",
    "    return None\n",
    "\n",
    "base_url = \"https://napoleoncat.com/stats/facebook-users-in-indonesia/\"\n",
    "years = range(2019, 2025)  # Change the range according to your requirements\n",
    "months = range(1, 13)\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        url = f\"{base_url}{year}/{month:02d}/\"\n",
    "        total_users = extract_facebook_users(url)\n",
    "        if total_users:\n",
    "            print(f\"In {year}/{month:02d}, total Facebook users: {total_users}\")\n",
    "        else:\n",
    "            print(f\"No data found for {year}/{month:02d}\")\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "data = [\n",
    "    {\"year_month\": \"2019/01\", \"total_users\": \"136 960 000\"},\n",
    "    {\"year_month\": \"2019/02\", \"total_users\": \"138 310 000\"},\n",
    "    {\"year_month\": \"2019/03\", \"total_users\": \"115 580 000\"},\n",
    "    {\"year_month\": \"2019/04\", \"total_users\": \"119 870 000\"},\n",
    "    {\"year_month\": \"2019/05\", \"total_users\": \"120 330 000\"},\n",
    "    {\"year_month\": \"2019/06\", \"total_users\": \"123 030 000\"},\n",
    "    {\"year_month\": \"2019/07\", \"total_users\": \"125 260 000\"},\n",
    "    {\"year_month\": \"2019/08\", \"total_users\": \"123 300 000\"},\n",
    "    {\"year_month\": \"2019/09\", \"total_users\": \"149 910 000\"},\n",
    "    {\"year_month\": \"2019/10\", \"total_users\": \"151 040 000\"},\n",
    "    {\"year_month\": \"2019/11\", \"total_users\": \"151 660 000\"},\n",
    "    {\"year_month\": \"2019/12\", \"total_users\": \"152 970 000\"},\n",
    "    {\"year_month\": \"2020/01\", \"total_users\": \"152 890 000\"},\n",
    "    {\"year_month\": \"2020/02\", \"total_users\": \"151 510 000\"},\n",
    "    {\"year_month\": \"2020/03\", \"total_users\": \"153 440 000\"},\n",
    "    {\"year_month\": \"2020/04\", \"total_users\": \"158 160 000\"},\n",
    "    {\"year_month\": \"2020/05\", \"total_users\": \"161 980 000\"},\n",
    "    {\"year_month\": \"2020/06\", \"total_users\": \"163 700 000\"},\n",
    "    {\"year_month\": \"2020/07\", \"total_users\": \"183 800 000\"},\n",
    "    {\"year_month\": \"2020/08\", \"total_users\": \"166 500 000\"},\n",
    "    {\"year_month\": \"2020/09\", \"total_users\": \"171 200 000\"},\n",
    "    {\"year_month\": \"2020/10\", \"total_users\": \"168 400 000\"},\n",
    "    {\"year_month\": \"2020/11\", \"total_users\": \"169 700 000\"},\n",
    "    {\"year_month\": \"2020/12\", \"total_users\": \"170 600 000\"},\n",
    "    {\"year_month\": \"2021/01\", \"total_users\": \"171 800 000\"},\n",
    "    {\"year_month\": \"2021/02\", \"total_users\": \"173 000 000\"},\n",
    "    {\"year_month\": \"2021/03\", \"total_users\": \"175 300 000\"},\n",
    "    {\"year_month\": \"2021/04\", \"total_users\": \"175 400 000\"},\n",
    "    {\"year_month\": \"2021/05\", \"total_users\": \"176 800 000\"},\n",
    "    {\"year_month\": \"2021/06\", \"total_users\": \"176 500 000\"},\n",
    "    {\"year_month\": \"2021/07\", \"total_users\": \"179 600 000\"},\n",
    "    {\"year_month\": \"2021/08\", \"total_users\": \"187 600 000\"},\n",
    "    {\"year_month\": \"2021/09\", \"total_users\": \"191 100 000\"},\n",
    "    {\"year_month\": \"2021/10\", \"total_users\": \"188 800 000\"},\n",
    "    {\"year_month\": \"2021/11\", \"total_users\": \"188 000 000\"},\n",
    "    {\"year_month\": \"2021/12\", \"total_users\": \"188 000 000\"},\n",
    "    {\"year_month\": \"2022/01\", \"total_users\": \"196 700 000\"},\n",
    "    {\"year_month\": \"2022/02\", \"total_users\": \"191 200 000\"},\n",
    "    {\"year_month\": \"2022/03\", \"total_users\": \"200 200 000\"},\n",
    "    {\"year_month\": \"2022/04\", \"total_users\": \"197 000 000\"},\n",
    "    {\"year_month\": \"2022/05\", \"total_users\": \"203 800 000\"},\n",
    "    {\"year_month\": \"2022/06\", \"total_users\": \"202 400 000\"},\n",
    "    {\"year_month\": \"2022/07\", \"total_users\": \"202 200 000\"},\n",
    "    {\"year_month\": \"2022/08\", \"total_users\": \"195 200 000\"},\n",
    "    {\"year_month\": \"2022/09\", \"total_users\": \"188 900 000\"},\n",
    "    {\"year_month\": \"2022/10\", \"total_users\": \"179 600 000\"},\n",
    "    {\"year_month\": \"2022/11\", \"total_users\": \"179 000 000\"},\n",
    "    {\"year_month\": \"2022/12\", \"total_users\": \"178 700 000\"},\n",
    "    {\"year_month\": \"2023/01\", \"total_users\": \"172 300 000\"},\n",
    "    {\"year_month\": \"2023/02\", \"total_users\": \"191 400 000\"},\n",
    "    {\"year_month\": \"2023/03\", \"total_users\": \"184 800 000\"},\n",
    "    {\"year_month\": \"2023/04\", \"total_users\": \"194 200 000\"},\n",
    "    {\"year_month\": \"2023/05\", \"total_users\": \"195 300 000\"},\n",
    "    {\"year_month\": \"2023/06\", \"total_users\": \"198 600 000\"},\n",
    "    {\"year_month\": \"2023/07\", \"total_users\": \"191 400 000\"},\n",
    "    {\"year_month\": \"2023/08\", \"total_users\": \"205 400 000\"},\n",
    "    {\"year_month\": \"2023/09\", \"total_users\": \"194 300 000\"},\n",
    "    {\"year_month\": \"2023/10\", \"total_users\": \"198 300 000\"},\n",
    "    {\"year_month\": \"2023/11\", \"total_users\": \"179 500 000\"},\n",
    "    {\"year_month\": \"2023/12\", \"total_users\": \"168 410 600\"},\n",
    "    {\"year_month\": \"2024/01\", \"total_users\": \"173 700 000\"},\n",
    "    {\"year_month\": \"2024/02\", \"total_users\": \"172 100 000\"},\n",
    "    {\"year_month\": \"2024/03\", \"total_users\": \"174 000 000\"},\n",
    "    {\"year_month\": \"2024/04\", \"total_users\": \"174 300 000\"},\n",
    "    {\"year_month\": \"2024/05\", \"total_users\": \"174 000 000\"}\n",
    "]\n",
    "\n",
    "# Convert data to JSON\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "\n",
    "# Group data by year\n",
    "yearly_data = defaultdict(list)\n",
    "for entry in data:\n",
    "    year = entry[\"year_month\"].split(\"/\")[0]\n",
    "    yearly_data[year].append(int(entry[\"total_users\"].replace(\" \", \"\")))\n",
    "\n",
    "# Calculate average user count for each year\n",
    "average_users = {year: sum(users) / len(users) for year, users in yearly_data.items()}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(average_users.keys(), average_users.values(), marker='o', linestyle='-')\n",
    "plt.title('Average Facebook Users Per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Users (in millions)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TikTok user data\n",
    "tiktok_data = {\n",
    "    \"2021\": 32_000_000,\n",
    "    \"2022\": 92_070_000,\n",
    "    \"2023\": 109_900_000,\n",
    "    \"2024\": 126_800_000\n",
    "}\n",
    "\n",
    "# Plotting TikTok data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tiktok_data.keys(), tiktok_data.values(), marker='o', linestyle='-')\n",
    "plt.title('Estimate TikTok Users Per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Estimate Users (in millions)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_academic_subjects['Average'] = (hashtag_academic_subjects['Lower Value'] + hashtag_academic_subjects['Upper Value']) / 2\n",
    "hashtag_art['Average'] = (hashtag_art['Lower Value'] + hashtag_art['Upper Value']) / 2\n",
    "hashtag_education['Average'] = (hashtag_education['Lower Value'] + hashtag_education['Upper Value']) / 2\n",
    "hashtag_language['Average'] = (hashtag_language['Lower Value'] + hashtag_language['Upper Value']) / 2\n",
    "hashtag_life_skills['Average'] = (hashtag_life_skills['Lower Value'] + hashtag_life_skills['Upper Value']) / 2\n",
    "\n",
    "hashtag_eat['Average'] = (hashtag_eat['Lower Value'] + hashtag_eat['Upper Value']) / 2\n",
    "hashtag_travel['Average'] = (hashtag_travel['Lower Value'] + hashtag_travel['Upper Value']) / 2\n",
    "hashtag_sport['Average'] = (hashtag_sport['Lower Value'] + hashtag_sport['Upper Value']) / 2\n",
    "hashtag_gaming['Average'] = (hashtag_gaming['Lower Value'] + hashtag_gaming['Upper Value']) / 2\n",
    "hashtag_shopping['Average'] = (hashtag_shopping['Lower Value'] + hashtag_shopping['Upper Value']) / 2\n",
    "all_hashtag_education['Average'] = (all_hashtag_education['Lower Value'] + all_hashtag_education['Upper Value']) / 2\n",
    "\n",
    "\n",
    "\n",
    "result_df_age_group['Average'] = (result_df_age_group['Lower Value'] + result_df_age_group['Upper Value']) / 2\n",
    "result_df_gender['Average'] = (result_df_gender['Lower Value'] + result_df_gender['Upper Value']) / 2\n",
    "result_df_connection_type['Average'] = (result_df_connection_type['Lower Value'] + result_df_connection_type['Upper Value']) / 2\n",
    "result_df_device['Average'] = (result_df_device['Lower Value'] + result_df_device['Upper Value']) / 2\n",
    "\n",
    "result_df_language['Average'] = (result_df_language['Lower Value'] + result_df_language['Upper Value']) / 2\n",
    "\n",
    "sorted_regency_audience_all = regency_audience_all.sort_values(by='Location')\n",
    "sorted_regency_audience_all.reset_index(drop=True, inplace=True)\n",
    "sorted_regency_audience_education = regency_audience_education.sort_values(by='Location')\n",
    "sorted_regency_audience_education.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "sorted_regency_audience_all['Average'] = (sorted_regency_audience_all['Lower Value'] + sorted_regency_audience_all['Upper Value']) / 2\n",
    "sorted_regency_audience_education['Average'] = (sorted_regency_audience_education['Lower Value'] + sorted_regency_audience_education['Upper Value']) / 2\n",
    "\n",
    "merged_df_academic_subjects = pd.merge(hashtag_academic_subjects, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_art = pd.merge(hashtag_art, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_education = pd.merge(hashtag_education, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_language = pd.merge(hashtag_language, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_life_skills = pd.merge(hashtag_life_skills, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "\n",
    "merged_df_hashtag_eat = pd.merge(hashtag_eat, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_hashtag_travel = pd.merge(hashtag_travel, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_hashtag_sport = pd.merge(hashtag_sport, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_hashtag_gaming = pd.merge(hashtag_gaming, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "merged_df_hashtag_shopping = pd.merge(hashtag_shopping, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "\n",
    "merged_df_all_hashtag_education = pd.merge(all_hashtag_education, sorted_regency_audience_all[['Location', 'Average']], on='Location', suffixes=('', '_regency'))\n",
    "\n",
    "\n",
    "pivot_df_connection_type= result_df_connection_type.pivot(index='Location', columns='Connection Type', values='Average')\n",
    "pivot_df_connection_type.reset_index(inplace=True)\n",
    "\n",
    "pivot_df_gender = result_df_gender.pivot(index='Location', columns='Gender', values='Average')\n",
    "pivot_df_gender.reset_index(inplace=True)\n",
    "\n",
    "pivot_df_language = result_df_language.pivot(index='Location', columns='Language', values='Average')\n",
    "pivot_df_language.reset_index(inplace=True)\n",
    "\n",
    "pivot_df_age_group = result_df_age_group.pivot(index='Location', columns='Age Group', values='Average')\n",
    "pivot_df_age_group.reset_index(inplace=True)\n",
    "\n",
    "pivot_df_device = result_df_device.pivot(index='Location', columns='Device', values='Average')\n",
    "pivot_df_device.reset_index(inplace=True)\n",
    "raw_count_df = (pivot_df_connection_type.merge(pivot_df_gender, on='Location')\n",
    "                .merge(pivot_df_language, on='Location')\n",
    "                .merge(pivot_df_age_group, on='Location')\n",
    "                .merge(pivot_df_device, on='Location')\n",
    "                .merge(regencyoffline, on='Location'))\n",
    "\n",
    "merged_df_academic_subjects = merged_df_academic_subjects.rename(columns={'Average': 'Academic Subject Hashtag'})\n",
    "merged_df_art = merged_df_art.rename(columns={'Average': 'Art Hashtag'})\n",
    "merged_df_education = merged_df_education.rename(columns={'Average': 'Education Hashtag'})\n",
    "merged_df_language = merged_df_language.rename(columns={'Average': 'Language Hashtag'})\n",
    "merged_df_life_skills = merged_df_life_skills.rename(columns={'Average': 'Life Skills Hashtag'})\n",
    "merged_sorted_regency_audience_education = sorted_regency_audience_education.rename(columns={'Average': 'Education Interest'})\n",
    "merged_sorted_regency_audience_all = sorted_regency_audience_all.rename(columns={'Average': 'All User'})\n",
    "\n",
    "merged_df_hashtag_eat= merged_df_hashtag_eat.rename(columns={'Average': 'Food Hashtag'})\n",
    "merged_df_hashtag_travel= merged_df_hashtag_travel.rename(columns={'Average': 'Travel Hashtag'})\n",
    "merged_df_hashtag_sport= merged_df_hashtag_sport.rename(columns={'Average': 'Sport Hashtag'})\n",
    "merged_df_hashtag_gaming= merged_df_hashtag_gaming.rename(columns={'Average': 'Gaming Hashtag'})\n",
    "merged_df_hashtag_shopping= merged_df_hashtag_shopping.rename(columns={'Average': 'Shopping Hashtag'})\n",
    "merged_df_all_hashtag_education= merged_df_all_hashtag_education.rename(columns={'Average': 'All Educational Hashtag'})\n",
    "\n",
    "# Merge these new columns into the existing raw_count_df dataframe\n",
    "raw_count_df = raw_count_df.merge(merged_df_academic_subjects[['Location', 'Academic Subject Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_art[['Location', 'Art Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_education[['Location', 'Education Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_language[['Location', 'Language Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_life_skills[['Location', 'Life Skills Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_sorted_regency_audience_education[['Location', 'Education Interest']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_sorted_regency_audience_all[['Location', 'All User']], on='Location', how='left')\n",
    "\n",
    "raw_count_df = raw_count_df.merge(merged_df_hashtag_eat[['Location', 'Food Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_hashtag_travel[['Location', 'Travel Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_hashtag_sport[['Location', 'Sport Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_hashtag_gaming[['Location', 'Gaming Hashtag']], on='Location', how='left')\n",
    "raw_count_df = raw_count_df.merge(merged_df_hashtag_shopping[['Location', 'Shopping Hashtag']], on='Location', how='left')\n",
    "\n",
    "raw_count_df = raw_count_df.merge(merged_df_all_hashtag_education[['Location', 'All Educational Hashtag']], on='Location', how='left')\n",
    "\n",
    "\n",
    "raw_count_df['2G'] = raw_count_df['2G'] / raw_count_df['All User']\n",
    "raw_count_df['4G'] = raw_count_df['4G'] / raw_count_df['All User']\n",
    "raw_count_df['Wi-Fi'] = raw_count_df['Wi-Fi'] / raw_count_df['All User']\n",
    "raw_count_df['Female'] = raw_count_df['Female'] / raw_count_df['All User']\n",
    "raw_count_df['Male'] = raw_count_df['Male'] / raw_count_df['All User']\n",
    "raw_count_df['English'] = raw_count_df['English'] / raw_count_df['All User']\n",
    "raw_count_df['English , Indonesia'] = raw_count_df['English , Indonesia'] / raw_count_df['All User']\n",
    "raw_count_df['Indonesia'] = raw_count_df['Indonesia'] / raw_count_df['All User']\n",
    "raw_count_df['18-24'] = raw_count_df['18-24'] / raw_count_df['All User']\n",
    "raw_count_df['25-34'] = raw_count_df['25-34'] / raw_count_df['All User']\n",
    "raw_count_df['35-44'] = raw_count_df['35-44'] / raw_count_df['All User']\n",
    "raw_count_df['45-54'] = raw_count_df['45-54'] / raw_count_df['All User']\n",
    "raw_count_df['55-100'] = raw_count_df['55-100'] / raw_count_df['All User']\n",
    "raw_count_df['Art Hashtag'] = raw_count_df['Art Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Education Hashtag'] = raw_count_df['Education Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Language Hashtag'] = raw_count_df['Language Hashtag'] / raw_count_df['All User'] \n",
    "raw_count_df['Life Skills Hashtag'] = raw_count_df['Life Skills Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Academic Subject Hashtag'] = raw_count_df['Academic Subject Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Shopping Hashtag'] = raw_count_df['Shopping Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Sport Hashtag'] = raw_count_df['Sport Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Travel Hashtag'] = raw_count_df['Travel Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Gaming Hashtag'] = raw_count_df['Gaming Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['Food Hashtag'] = raw_count_df['Food Hashtag'] / raw_count_df['All User']\n",
    "raw_count_df['All Educational Hashtag'] = raw_count_df['All Educational Hashtag'] / raw_count_df['All User']\n",
    "\n",
    "\n",
    "raw_count_df['Android'] = raw_count_df['Android'] / raw_count_df['All User']\n",
    "raw_count_df['iOs'] = raw_count_df['iOs'] / raw_count_df['All User']\n",
    "raw_count_df['Education Interest'] = raw_count_df['Education Interest'] / raw_count_df['All User']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the target variable\n",
    "target = 'Education Hashtag'\n",
    "\n",
    "# Define the predictors\n",
    "\n",
    "# Prepare the data for statsmodels\n",
    "X =  raw_count_df.drop(columns=[target])\n",
    "y = raw_count_df[target]\n",
    "\n",
    "# Add a constant to the predictors (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform OLS regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the target variable\n",
    "target = 'Education Hashtag'\n",
    "\n",
    "# Define the subsets of predictors\n",
    "hashtags = [\"Academic Subject Hashtag\", \"Art Hashtag\", \"Language Hashtag\", \"Life Skills Hashtag\",\n",
    "            \"Food Hashtag\", \"Travel Hashtag\", \"Sport Hashtag\", \"Gaming Hashtag\", \"Shopping Hashtag\"]\n",
    "demographics = [\"2G\", \"4G\", \"Wi-Fi\", \"Female\", \"Male\", \"English\", \"Indonesia\",\n",
    "                \"18-24\", \"25-34\", \"35-44\", \"Android\", \"iOs\"]\n",
    "offline_data = [\"Poorness\"]\n",
    "\n",
    "# Prepare the data for statsmodels\n",
    "def perform_ols(predictors, target):\n",
    "    X = raw_count_df[predictors]\n",
    "    y = raw_count_df[target]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model\n",
    "\n",
    "# Perform OLS for each subset\n",
    "model_hashtags = perform_ols(hashtags, target)\n",
    "model_demographics = perform_ols(demographics, target)\n",
    "model_offline = perform_ols(offline_data, target)\n",
    "\n",
    "# Print the summary of each regression\n",
    "print(model_hashtags.summary())\n",
    "print(model_demographics.summary())\n",
    "print(model_offline.summary())\n",
    "\n",
    "summary_hashtags = model_hashtags.summary2().tables[1]\n",
    "summary_demographics = model_demographics.summary2().tables[1]\n",
    "summary_offline = model_offline.summary2().tables[1]\n",
    "# Add a column to identify the model\n",
    "summary_hashtags['Model'] = 'Hashtags'\n",
    "summary_demographics['Model'] = 'Demographics'\n",
    "summary_offline['Model'] = 'Offline'\n",
    "\n",
    "# Concatenate the summaries into a single DataFrame\n",
    "summary_table = pd.concat([summary_hashtags, summary_demographics, summary_offline])\n",
    "\n",
    "# Reset the index\n",
    "summary_table.reset_index(inplace=True)\n",
    "latex_summary1 = model_hashtags.summary().as_latex()\n",
    "latex_summary2 = model_demographics.summary().as_latex()\n",
    "\n",
    "\n",
    "print(latex_summary1)\n",
    "print(latex_summary2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'All Educational Hashtag'\n",
    "\n",
    "# Demographic features\n",
    "demographic_features = ['18-24', '25-34', 'Android', 'iOs','2G', 'Wi-Fi', 'Female', 'Male']\n",
    "\n",
    "\n",
    "# Hashtag features\n",
    "hashtag_features = [\n",
    "                    'Food Hashtag', 'Travel Hashtag', 'Sport Hashtag', 'Gaming Hashtag', 'Shopping Hashtag', \n",
    "                    ]\n",
    "def perform_ols(features, target, df):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X = sm.add_constant(X)  # Add a constant to the predictors (intercept)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(model.summary())\n",
    "print(\"Demographic Model:\")\n",
    "perform_ols(demographic_features, target, raw_count_df)\n",
    "\n",
    "print(\"\\nHashtag Model:\")\n",
    "perform_ols(hashtag_features, target, raw_count_df)\n",
    "combined_features = demographic_features +hashtag_features\n",
    "\n",
    "print(\"\\nCombined Model:\")\n",
    "perform_ols(combined_features, target, raw_count_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average values for the specified hashtags\n",
    "hashtags = ['Food Hashtag', 'Travel Hashtag', 'Gaming Hashtag', 'Shopping Hashtag', 'All Educational Hashtag' , 'Sport Hashtag']\n",
    "average_values = raw_count_df[hashtags].mean()\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "average_values.plot(kind='bar')\n",
    "plt.title('Average Values of Selected Hashtags')\n",
    "plt.xlabel('Hashtags')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the target variable\n",
    "target = 'All Educational Hashtag'\n",
    "\n",
    "# Define features and target\n",
    "X = raw_count_df.drop(columns=[target, 'Art Hashtag', 'Language Hashtag', 'Academic Subject Hashtag', 'Life Skills Hashtag', 'Travel Hashtag', 'Food Hashtag', 'Sport Hashtag', 'Shopping Hashtag', 'Gaming Hashtag' , 'Location'])\n",
    "Y = raw_count_df[target]\n",
    "\n",
    "correlations = X.corrwith(Y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features (after normalization)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Gradient Boosting Regressor Model\n",
    "model_gb = GradientBoostingRegressor()\n",
    "model_gb.fit(X_train_scaled, Y_train)\n",
    "Y_pred_gb = model_gb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "mse_gb = mean_squared_error(Y_test, Y_pred_gb)\n",
    "r2_gb = r2_score(Y_test, Y_pred_gb)\n",
    "\n",
    "# Print the custom summary\n",
    "print(\"Gradient Boosting Regressor Summary\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f'Mean Squared Error (MSE): {mse_gb:.4f}')\n",
    "print(f'R-squared: {r2_gb:.4f}')\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in zip(X.columns, model_gb.feature_importances_):\n",
    "    print(f'{feature}: {importance:.4f}')\n",
    "\n",
    "# Pairwise comparison plots with R-squared annotation\n",
    "num_features = X.shape[1]\n",
    "num_cols = 5\n",
    "num_rows = math.ceil(num_features / num_cols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, num_rows * 4))\n",
    "\n",
    "for i, col in enumerate(X.columns):\n",
    "    # Fit individual feature regression\n",
    "    feature_model = GradientBoostingRegressor()\n",
    "    feature_model.fit(X_train_scaled[:, i].reshape(-1, 1), Y_train)\n",
    "    y_pred_feature = feature_model.predict(X_train_scaled[:, i].reshape(-1, 1))\n",
    "    r2_feature = r2_score(Y_train, y_pred_feature)\n",
    "    \n",
    "    sns.regplot(x=X_train[col], y=Y_train, ax=axs[i // num_cols, i % num_cols], scatter_kws={'s': 5}, line_kws={'color': 'blue'})\n",
    "    axs[i // num_cols, i % num_cols].set_ylabel('Predicted')\n",
    "    axs[i // num_cols, i % num_cols].set_title(f'R-squared: {r2_feature:.2f}, Correlation: {correlations[col]:.2f}')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, num_rows * num_cols):\n",
    "    fig.delaxes(axs[j // num_cols, j % num_cols])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "quartiles, bin_edges = pd.qcut(raw_count_df['Poorness'], 3, labels=['urban', 'suburban', 'rural'], retbins=True)\n",
    "# Add the \"Color\" column\n",
    "raw_count_df['Color'] = quartiles\n",
    "\n",
    "# Display the updated DataFrame\n",
    "# Calculate differences in medians for rural vs urban\n",
    "urban = raw_count_df[raw_count_df['Color'] == 'urban']\n",
    "rural = raw_count_df[raw_count_df['Color'] == 'rural']\n",
    "\n",
    "variables = ['2G',  '4G',  'Wi-Fi', 'Female', 'Male', 'Poorness' ,'Education Hashtag', 'Art Hashtag','Life Skills Hashtag' ,'Academic Subject Hashtag', 'iOs', 'Android' , 'English' , 'Indonesia', '18-24' ,'Gaming Hashtag', 'Shopping Hashtag', 'Travel Hashtag', 'Sport Hashtag' , 'Food Hashtag']\n",
    "\n",
    "diff_medians = []\n",
    "for var in variables:\n",
    "    median_urban = urban[var].median()\n",
    "    median_rural = rural[var].median()\n",
    "    diff = median_urban - median_rural\n",
    "    p_value = stats.mannwhitneyu(urban[var], rural[var]).pvalue\n",
    "    diff_medians.append((var, diff, p_value))\n",
    "\n",
    "# Convert to DataFrame\n",
    "diff_medians_df = pd.DataFrame(diff_medians, columns=['Variable', 'Difference', 'p_value'])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Create caterpillar plot\n",
    "for i, row in diff_medians_df.iterrows():\n",
    "    ax.plot([row['Difference'], row['Difference']], [i - 0.4, i + 0.4], color='grey')\n",
    "    ax.scatter(row['Difference'], i, color='blue' if row['p_value'] < 0.05 else 'grey')\n",
    "    ax.text(row['Difference'], i, f\"{row['Difference']:.2f}\", va='center', ha='left' if row['Difference'] > 0 else 'right', color='blue' if row['p_value'] < 0.05 else 'grey')\n",
    "\n",
    "ax.set_yticks(range(len(diff_medians_df)))\n",
    "ax.set_yticklabels(diff_medians_df['Variable'])\n",
    "ax.axvline(x=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('more rural                                        more urban')\n",
    "ax.set_title('Distribution of Difference in Medians between Urban and Rural Areas in Indonesian Regencies')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_counts = raw_count_df[\"Color\"].value_counts()\n",
    "print(\"\\nCounts of each category in the 'Color' column:\")\n",
    "print(color_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a 2x2 grid of subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# First scatter plot\n",
    "sns.scatterplot(data=raw_count_df, x='Education Hashtag', y='Population', hue='Color', palette='viridis', s=100, ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Education Hashtag vs. Population')\n",
    "axs[0, 0].set_xlabel('Education Hashtag')\n",
    "axs[0, 0].set_ylabel('Population')\n",
    "\n",
    "# Second scatter plot\n",
    "sns.scatterplot(data=raw_count_df, x='Life Skills Hashtag', y='Population', hue='Color', palette='viridis', s=100, ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Life Skills Hashtag vs. Population')\n",
    "axs[0, 1].set_xlabel('Life Skills Hashtag')\n",
    "axs[0, 1].set_ylabel('Population')\n",
    "\n",
    "# Third scatter plot\n",
    "sns.scatterplot(data=raw_count_df, x='Academic Subject Hashtag', y='Population', hue='Color', palette='viridis', s=100, ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Academic Subject Hashtag vs. Population')\n",
    "axs[1, 0].set_xlabel('Academic Subject Hashtag')\n",
    "axs[1, 0].set_ylabel('Population')\n",
    "\n",
    "# Fourth scatter plot\n",
    "sns.scatterplot(data=raw_count_df, x='Art Hashtag', y='Population', hue='Color', palette='viridis', s=100, ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Art Hashtag vs. Population')\n",
    "axs[1, 1].set_xlabel('Art Hashtag')\n",
    "axs[1, 1].set_ylabel('Population')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "plt.legend(title='Area Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hashtag_categories = [\n",
    "    'Education Hashtag', \n",
    "    'Life Skills Hashtag', \n",
    "    'Academic Subject Hashtag', \n",
    "    'Art Hashtag'\n",
    "]\n",
    "\n",
    "# Function to find and print the highest rate for each hashtag category in each area type\n",
    "def print_highest_rate_per_category(df, categories, area_column='Color', location_column='Location'):\n",
    "    for category in categories:\n",
    "        print(f\"Highest rates for {category}:\")\n",
    "        \n",
    "        # Iterate through each unique area type (Color)\n",
    "        for area_type in df[area_column].unique():\n",
    "            # Filter the dataframe for the current area type\n",
    "            area_df = df[df[area_column] == area_type]\n",
    "            \n",
    "            # Find the row with the maximum value for the current category\n",
    "            max_row = area_df.loc[area_df[category].idxmax()]\n",
    "            \n",
    "            # Extract the location and the max value\n",
    "            location = max_row[location_column]\n",
    "            max_value = max_row[category]\n",
    "            \n",
    "            print(f\"{area_type}: {max_value} at {location}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Call the function\n",
    "print_highest_rate_per_category(raw_count_df, hashtag_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_count_df2 = raw_count_df.drop(columns=['Location', 'Color', \"3G\" , \"5G\" , \"Poorness\", \"English , Indonesia\" , 'All User' , \"Education Interest\"], errors='ignore')\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = raw_count_df2.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# If you want to focus on correlations with specific variables, you can extract those correlations:\n",
    "# For example, if you want to analyze the correlation of 'Education Hashtag' with all other variables:\n",
    "education_correlations = correlation_matrix['Education Hashtag']\n",
    "\n",
    "# Display correlations with 'Education Hashtag'\n",
    "print(\"\\nCorrelation with 'Education Hashtag':\")\n",
    "print(education_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the plot\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "\n",
    "# Add title and rotate y-axis labels for better readability\n",
    "plt.title('Correlation Matrix')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'D:\\Thesis\\Data\\province_df.txt'\n",
    "## result_df_device_age_regency.to_csv(file_path, sep='\\t', index=False)\n",
    "province_df = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = r'D:\\Thesis\\Data\\province_df.txt'\n",
    "#province_df.to_csv(file_path, sep='\\t', index= False)\n",
    "# Define thresholds for classification\n",
    "def classify_province(poor_population_percentage):\n",
    "    if poor_population_percentage < 0.06:\n",
    "        return 'Urban'\n",
    "    elif poor_population_percentage < 0.08:\n",
    "        return 'Suburban'\n",
    "    else:\n",
    "        return 'Rural'\n",
    "\n",
    "# Create a new column for classification\n",
    "province_df['Classification'] = province_df['Poor Population Percentage'].apply(classify_province)\n",
    "\n",
    "# Check the distribution of classifications\n",
    "print(province_df['Classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_df_2 = province_df.drop(columns=[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Assuming province_df is already defined\n",
    "# Compute Pearson and Spearman correlations\n",
    "pearson_corr = province_df_2.corr(method='pearson')\n",
    "spearman_corr = province_df_2.corr(method='spearman')\n",
    "\n",
    "# Display correlation matrices\n",
    "print(\"Pearson Correlation:\\n\", pearson_corr)\n",
    "print(\"Spearman Correlation:\\n\", spearman_corr)\n",
    "\n",
    "# Plot heatmap of Pearson correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot heatmap of Spearman correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Spearman Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select the columns to plot\n",
    "columns_to_plot = province_df_2.drop(columns=['#Educational_Hashtag', 'Classification', 'Cluster' ,\"Female\", \"Male\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-100\", \"PCA1\", \"PCA2\", \"PCA3\", \"TSNE1\", \"TSNE2\", \"#general_education\" , \"Wi-Fi\", \"2G\", \"4G\" ]).columns\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=(len(columns_to_plot) + 1) // 2, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each column against #Educational_Hashtag\n",
    "for ax, column in zip(axes, columns_to_plot):\n",
    "    sns.scatterplot(x=province_df_2[column], y=province_df_2['#Educational_Hashtag'], ax=ax)\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('#Educational_Hashtag')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for i in range(len(columns_to_plot), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming province_df_2 is already defined and cleaned\n",
    "# Select the relevant columns for regression\n",
    "X = province_df_2[['High School Completion Rate', 'Poor Population Percentage', \n",
    "                   'Number Of University', 'Number Of Teacher/Professor', 'Number Of Students', 'Android', 'iOs']]\n",
    "y = province_df_2['#Educational_Hashtag']\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression model\n",
    "print(model.summary())\n",
    "\n",
    "# Plotting the regression coefficients\n",
    "coefficients = model.params[1:]  # Exclude the intercept\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=coefficients.index, y=coefficients.values)\n",
    "plt.title('Regression Coefficients')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize differences using boxplots\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='Classification', y='#Educational_Hashtag', data=province_df)\n",
    "plt.title('General Education by Classification')\n",
    "plt.show()\n",
    "\n",
    "# Perform statistical tests (e.g., ANOVA) to compare means\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# ANOVA test between classifications\n",
    "rural = province_df[province_df['Classification'] == 'Rural']['Android']\n",
    "suburban = province_df[province_df['Classification'] == 'Suburban']['Android']\n",
    "urban = province_df[province_df['Classification'] == 'Urban']['Android']\n",
    "\n",
    "f_stat, p_val = f_oneway(rural, suburban, urban)\n",
    "print(f'ANOVA F-statistic: {f_stat}, p-value: {p_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(province_df_2.drop(columns=['#Educational_Hashtag' , \"Classification\"]))\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "province_df_2['PCA1'] = pca_components[:, 0]\n",
    "province_df_2['PCA2'] = pca_components[:, 1]\n",
    "\n",
    "# Plotting the PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', data=province_df_2, hue='Classification')\n",
    "plt.title('PCA of Government and Demographic Attributes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "province_df_2['Cluster'] = kmeans.fit_predict(pca_components)\n",
    "\n",
    "# Plotting the PCA results with clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', data=province_df_2, hue='Cluster', palette='viridis')\n",
    "plt.title('PCA of Government and Demographic Attributes with K-means Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(province_df_2.drop(columns=['#Educational_Hashtag', 'Classification']))\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Check explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Variance explained by each component: \", explained_variance)\n",
    "print(\"Total variance explained by first two components: \", sum(explained_variance[:2]))\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "province_df_2['PCA1'] = pca_components[:, 0]\n",
    "province_df_2['PCA2'] = pca_components[:, 1]\n",
    "\n",
    "# Plotting the PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', data=province_df_2, hue='Classification')\n",
    "plt.title('PCA of Government and Demographic Attributes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAPPING \n",
    "\n",
    "import geopandas as gpd\n",
    "shp_file_path = r\"D:\\Thesis\\BATAS_PROVINSI_DESEMBER_2019_DUKCAPIL.shp\"\n",
    "gdf = gpd.read_file(shp_file_path)\n",
    "gdf = gdf.rename(columns={\"PROVINSI\": \"Location\"})\n",
    "# Create a mapping dictionary for location names\n",
    "location_mapping = {\n",
    "    'ACEH': 'ACEH',\n",
    "    'BALI': 'BALI',\n",
    "    'BANGKA BELITUNG ISLANDS': 'KEPULAUAN BANGKA BELITUNG',\n",
    "    'BANTEN': 'BANTEN',\n",
    "    'BENGKULU': 'BENGKULU',\n",
    "    'CENTRAL JAVA': 'JAWA TENGAH',\n",
    "    'CENTRAL KALIMANTAN': 'KALIMANTAN TENGAH',\n",
    "    'CENTRAL SULAWESI': 'SULAWESI TENGAH',\n",
    "    'EAST JAVA': 'JAWA TIMUR',\n",
    "    'EAST KALIMANTAN': 'KALIMANTAN TIMUR',\n",
    "    'EAST NUSA TENGGARA': 'NUSA TENGGARA TIMUR',\n",
    "    'GORONTALO': 'GORONTALO',\n",
    "    'JAKARTA': 'DKI JAKARTA',\n",
    "    'JAMBI': 'JAMBI',\n",
    "    'LAMPUNG': 'LAMPUNG',\n",
    "    'MALUKU': 'MALUKU',\n",
    "    'NORTH KALIMANTAN': 'KALIMANTAN UTARA',\n",
    "    'NORTH MALUKU': 'MALUKU UTARA',\n",
    "    'NORTH SULAWESI': 'SULAWESI UTARA',\n",
    "    'NORTH SUMATRA': 'SUMATERA UTARA',\n",
    "    'PAPUA': 'PAPUA',\n",
    "    'RIAU': 'RIAU',\n",
    "    'RIAU ISLANDS': 'KEPULAUAN RIAU',\n",
    "    'SOUTH KALIMANTAN': 'KALIMANTAN SELATAN',\n",
    "    'SOUTH SULAWESI': 'SULAWESI SELATAN',\n",
    "    'SOUTH SUMATRA': 'SUMATERA SELATAN',\n",
    "    'SOUTHEAST SULAWESI': 'SULAWESI TENGGARA',\n",
    "    'WEST JAVA': 'JAWA BARAT',\n",
    "    'WEST KALIMANTAN': 'KALIMANTAN BARAT',\n",
    "    'WEST NUSA TENGGARA': 'NUSA TENGGARA BARAT',\n",
    "    'WEST PAPUA': 'PAPUA BARAT',\n",
    "    'WEST SULAWESI': 'SULAWESI BARAT',\n",
    "    'WEST SUMATRA': 'SUMATERA BARAT',\n",
    "    'YOGYAKARTA': 'DAERAH ISTIMEWA YOGYAKARTA'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Location' column\n",
    "province_df['Location'] = province_df['Location'].replace(location_mapping)\n",
    "\n",
    "# Convert the 'Location' column in province_df to uppercase\n",
    "province_df['Location'] = province_df['Location'].str.upper()\n",
    "\n",
    "# Merge your DataFrame with the GeoDataFrame\n",
    "merged_gdf = gdf.merge(province_df, on=\"Location\")\n",
    "\n",
    "# Ensure the classification order matches the colors\n",
    "classification_order = ['Rural', 'Suburban', 'Urban']\n",
    "classification_colors = {'Rural': 'green', 'Suburban': 'orange', 'Urban': 'blue'}\n",
    "cmap = plt.matplotlib.colors.ListedColormap(\n",
    "    [classification_colors[key] for key in classification_order]\n",
    ")\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot the boundaries\n",
    "merged_gdf.boundary.plot(ax=ax, linewidth=1)\n",
    "\n",
    "# Plot the provinces colored by classification\n",
    "merged_gdf.plot(column='Classification', ax=ax, legend=True,\n",
    "                legend_kwds={'title': \"Classification\"},\n",
    "                cmap=cmap, categories=classification_order)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title(\"Province Classification Across Indonesian Provinces\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to the shapefile\n",
    "shapefile_path = r\"D:\\Thesis\\BATAS KABUPATEN KOTA DESEMBER 2019 DUKCAPIL\\BATAS KABUPATEN KOTA DESEMBER 2019 DUKCAPIL.shp\"\n",
    "regencyoffline[\"Location\"] = regencyoffline[\"Location\"].str.upper()\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf.rename(columns={'KAB_KOTA': 'Location'})\n",
    "# Display the first few rows\n",
    "merged_gdf = gdf.merge(regencyoffline, how='left', left_on='Location', right_on='Location')\n",
    "\n",
    "# Plotting the merged GeoDataFrame\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot the known regions\n",
    "known_regions = merged_gdf[merged_gdf['Poorness'].notnull()]\n",
    "known_regions.plot(ax=ax, color='lightsalmon', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Plot the regions without data (colorless)\n",
    "gdf[~gdf['Location'].isin(known_regions['Location'])].plot(ax=ax, color='none', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Set plot title and show plot\n",
    "plt.title(\"Available Regencies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
